{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-06fffa32dec3>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /root/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /root/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From /root/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From /root/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /root/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting ./MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting ./MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /root/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist=input_data.read_data_sets('./MNIST_data',one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 28*28 被拉成一行了\n",
    "mnist.train.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 784)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.validation.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x,train_y=mnist.train.next_batch(20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 784)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取5000张图片\n",
    "test_x, test_y = mnist.test.next_batch(5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 图像的可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rc('image',cmap='binary')\n",
    "for i in range(10):#打印10张图\n",
    "    plt.subplot(2,5,i+1)\n",
    "    plt.imshow(train_x[i].reshape(28,28))\n",
    "    print(train_y[i])\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "plt.tight_layout()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 全连接神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model1():\n",
    "    model=Sequential()\n",
    "    model.add(Dense(784,activation='relu'))\n",
    "    model.add(Dense(100,activation='relu'))\n",
    "    model.add(Dense(100,activation='relu'))\n",
    "    model.add(Dense(10,activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=model1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.compile(optimizer='adam',loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 10s 486us/step - loss: 0.0918\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 9s 458us/step - loss: 0.0653\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 9s 461us/step - loss: 0.0462\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 9s 470us/step - loss: 0.0326\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 9s 460us/step - loss: 0.0329\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 9s 469us/step - loss: 0.0316\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 10s 479us/step - loss: 0.0277\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 9s 469us/step - loss: 0.0229\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 9s 463us/step - loss: 0.0215\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 9s 468us/step - loss: 0.0138\n"
     ]
    }
   ],
   "source": [
    "history=m.fit(train_x,train_y,epochs=10,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=m.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.966"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(pred.argmax(1),test_y.argmax(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import random\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_trans=transforms.Compose([\n",
    "    transforms.Resize(32),\n",
    "    transforms.ToTensor()\n",
    "#    transforms.Normalize(()())?<-参数mean和std来自于训练集，但是transform本身会在训练和评测的时候都会使用\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 图像的Normalize\n",
    "\n",
    "- 目的：将图片进行归一化的缩放|(x-mean)/std\n",
    "\n",
    "- 思考：图片归一化后，真的不存在小于0或者大于1的outlier了吗？ 不一定\n",
    "\n",
    "- 思考：归一化哪部分数据？A 训练集 B 评测集 C 训练集+评测集？ A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13251466"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(mnist.test.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31048024"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(mnist.test.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_trans=transforms.Compose([\n",
    "    transforms.Resize(32),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,),(0.3081,))#参数mean和std来自于训练集，但是transform本身会在训练和评测的时候都会使用\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train_data=datasets.MNIST('data',train=True,download=True,transform=data_trans)\n",
    "test_data=datasets.MNIST('data',train=False,download=True,transform=data_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train=int(len(train_data)*0.9)\n",
    "n_validation=len(train_data)-n_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,valid_data=torch.utils.data.random_split(train_data,[n_train,n_validation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54000 6000 10000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data),len(valid_data),len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 目前完成了数据集的制作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator=torch.utils.data.DataLoader(train_data,shuffle=True,batch_size=batch_size)\n",
    "valid_iterator=torch.utils.data.DataLoader(valid_data,batch_size=batch_size)\n",
    "test_iterator=torch.utils.data.DataLoader(test_data,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet,self).__init__()\n",
    "        #第一层conv1卷积层，in_channel=1,output_channel=6,kernel_size=5*5,input_size=32*32,output_size=28*28\n",
    "        self.conv1=nn.Conv2d(1,6,5)\n",
    "        #第二层conv2，output_channel=6 ,kernel 5*5,output_size=10*10,input_size=14*14\n",
    "        self.conv2=nn.Conv2d(6,16,5)\n",
    "        \n",
    "        self.fc1=nn.Linear(16*5*5,120)\n",
    "        \n",
    "        self.fc2=nn.Linear(120,80)\n",
    "        \n",
    "        self.fc3=nn.Linear(80,10)#不用增加softmax层，在cross_entropy的Loss中自动增加了Softmax\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=F.max_pool2d(F.relu(self.conv1(x)),2)\n",
    "        x=F.max_pool2d(F.relu(self.conv2(x)),2)\n",
    "        x=x.view(x.shape[0],-1)\n",
    "        x=F.relu(self.fc1(x))\n",
    "        x=F.relu(self.fc2(x))\n",
    "        x=self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 到此神经网络定义完毕\n",
    "\n",
    "## 载入模型并训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=LeNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeNet(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=80, bias=True)\n",
       "  (fc3): Linear(in_features=80, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 如何评价\n",
    "- 计算精确度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accu(fx,y):\n",
    "    pred=fx.max(1,keepdim=True)[1]\n",
    "    correct=pred.eq(y.view_as(pred)).sum()#得到该batch的准确度\n",
    "    acc=correct.float()/pred.shape[0]\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,device,iterator,optimizer,criterion):\n",
    "    epoch_loss=0#积累变量\n",
    "    epoch_acc=0#积累变量\n",
    "    model.train()#该函数表示PHASE=Train\n",
    "    \n",
    "    for (x,y) in iterator:#拿去每一个minibatch\n",
    "        x=x.to(device)\n",
    "        y=y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        fx=model(x)#进行forward\n",
    "        loss=criterion(fx,y)#计算Loss,train_loss\n",
    "        type(loss)\n",
    "        acc=accu(fx,y)#计算精确度，train_accu\n",
    "        loss.backward()#进行BP\n",
    "        optimizer.step()#统一更新模型\n",
    "        epoch_loss+=loss.item()\n",
    "        epoch_acc+=acc.item()\n",
    "        \n",
    "    return epoch_loss/len(iterator),epoch_acc/len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model,device,iterator,criterion):\n",
    "    epoch_loss=0\n",
    "    epoch_acc=0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for (x,y) in iterator:\n",
    "            x=x.to(device)\n",
    "            y=y.to(device)\n",
    "            fx=model(x)\n",
    "            loss=criterion(fx,y)\n",
    "            acc=accu(fx,y)\n",
    "            epoch_loss+=loss.item()\n",
    "            epoch_acc+=acc.item()\n",
    "    return epoch_loss/len(iterator),epoch_acc/len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=10\n",
    "model_dir='models'\n",
    "model_path=os.path.join(model_dir,'lenet_mnist.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_valid_loss=float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(model_dir):\n",
    "    os.makedirs(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1|Train Loss:0.233421141992354|Train Acc:0.9293666074485011|Val Loss:0.07848111389482275|Val Acc:0.9763408690056903\n",
      "Epoch:2|Train Loss:0.06469552075905258|Train Acc:0.9800552922826242|Val Loss:0.06426778717085402|Val Acc:0.9793882978723404\n",
      "Epoch:3|Train Loss:0.04806419984565527|Train Acc:0.9852944806712498|Val Loss:0.045799196033956525|Val Acc:0.9863696808510638\n",
      "Epoch:4|Train Loss:0.03583234349062658|Train Acc:0.9888304700077427|Val Loss:0.054408073207323854|Val Acc:0.9835438829787234\n",
      "Epoch:5|Train Loss:0.03144152051663265|Train Acc:0.990206605450237|Val Loss:0.03927518397648918|Val Acc:0.987533244680851\n",
      "Epoch:6|Train Loss:0.024257121384761767|Train Acc:0.9923294332778849|Val Loss:0.04480919138865268|Val Acc:0.9855385638297872\n",
      "Epoch:7|Train Loss:0.020660477313014427|Train Acc:0.9933167950236966|Val Loss:0.04023769577132895|Val Acc:0.988031914893617\n",
      "Epoch:8|Train Loss:0.018315879111641675|Train Acc:0.9940079482387028|Val Loss:0.04630079475092761|Val Acc:0.9873116136865413\n",
      "Epoch:9|Train Loss:0.014837993746976506|Train Acc:0.9954457938388626|Val Loss:0.05109678746474798|Val Acc:0.9858710106382979\n",
      "Epoch:10|Train Loss:0.0138844136894632|Train Acc:0.9952791765402843|Val Loss:0.0575203446156167|Val Acc:0.9842087765957447\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    train_loss,train_acc=train(model,device,train_iterator,optimizer,criterion)\n",
    "    valid_loss,valid_acc=evaluate(model,device,valid_iterator,criterion)\n",
    "    if valid_loss<best_valid_loss:#如果是最好的模型就保存到文件夹\n",
    "        best_valid_loss=valid_loss\n",
    "        torch.save(model.state_dict(),model_path)\n",
    "    print('Epoch:{0}|Train Loss:{1}|Train Acc:{2}|Val Loss:{3}|Val Acc:{4}'.format(epoch+1,train_loss,train_acc,valid_loss,valid_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 0.034958216913376645 | Test Acc: 0.987062101910828 |\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "test_loss, test_acc = evaluate(model, device, test_iterator, criterion)\n",
    "\n",
    "print('| Test Loss: {0} | Test Acc: {1} |'.format(test_loss,test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
