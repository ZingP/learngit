{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 模型定义\n",
    "- 在GoogLeNet的定义中去掉max_pool2 与 max_pool4，防止size因为池化降维而变成0，**注意在forward中也要做相应更改**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, **kwargs):\n",
    "        super(BasicConv2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, bias=False, **kwargs)\n",
    "        self.bn = nn.BatchNorm2d(out_channels, eps=0.001)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Inception(nn.Module):\n",
    "    def __init__(self, in_channels, n1_1, n3x3red, n3x3, n5x5red, n5x5, pool_plane):\n",
    "        super(Inception, self).__init__()\n",
    "        # first line\n",
    "        self.branch1x1 = BasicConv2d(in_channels, n1_1, kernel_size=1)\n",
    "\n",
    "        # second line\n",
    "        self.branch3x3 = nn.Sequential(\n",
    "            BasicConv2d(in_channels, n3x3red, kernel_size=1),\n",
    "            BasicConv2d(n3x3red, n3x3, kernel_size=3, padding=1)\n",
    "        )\n",
    "\n",
    "        # third line\n",
    "        self.branch5x5 = nn.Sequential(\n",
    "            BasicConv2d(in_channels, n5x5red, kernel_size=1),\n",
    "            BasicConv2d(n5x5red, n5x5, kernel_size=5, padding=2)\n",
    "        )\n",
    "\n",
    "        # fourth line\n",
    "        self.branch_pool = nn.Sequential(\n",
    "            nn.MaxPool2d(3, stride=1, padding=1),\n",
    "            BasicConv2d(in_channels, pool_plane, kernel_size=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        y1 = self.branch1x1(x)\n",
    "        y2 = self.branch3x3(x)\n",
    "        y3 = self.branch5x5(x)\n",
    "        y4 = self.branch_pool(x)\n",
    "        output = torch.cat([y1, y2, y3, y4], 1)\n",
    "        return output\n",
    "\n",
    "\n",
    "class GoogLeNet(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes=10):\n",
    "        super(GoogLeNet, self).__init__()\n",
    "\n",
    "        self.conv1 = BasicConv2d(in_channels, 64, kernel_size=7, stride=2, padding=3)\n",
    "\n",
    "        self.max_pool1 = nn.MaxPool2d(3, stride=2)\n",
    "\n",
    "        self.conv2 = BasicConv2d(64, 192, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # self.max_pool2 = nn.MaxPool2d(3, stride=2)\n",
    "\n",
    "        self.a3 = Inception(192, 64, 96, 128, 16, 32, 32)\n",
    "        self.b3 = Inception(256, 128, 128, 192, 32, 96, 64)\n",
    "\n",
    "        self.max_pool3 = nn.MaxPool2d(3, stride=2)\n",
    "\n",
    "        self.a4 = Inception(480, 192, 96, 208, 16, 48, 64)\n",
    "        self.b4 = Inception(512, 160, 112, 224, 24, 64, 64)\n",
    "        self.c4 = Inception(512, 128, 128, 256, 24, 64, 64)\n",
    "        self.d4 = Inception(512, 112, 144, 288, 32, 64, 64)\n",
    "        self.e4 = Inception(528, 256, 160, 320, 32, 128, 128)\n",
    "\n",
    "        # self.max_pool4 = nn.MaxPool2d(3, stride=2)\n",
    "\n",
    "        self.a5 = Inception(832, 256, 160, 320, 32, 128, 128)\n",
    "        self.b5 = Inception(832, 384, 192, 384, 48, 128, 128)\n",
    "\n",
    "        self.avg_pool = nn.AvgPool2d(7)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "\n",
    "        self.classifier = nn.Linear(1024, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.max_pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        # x = self.max_pool2(x)\n",
    "        x = self.a3(x)\n",
    "        x = self.b3(x)\n",
    "        x = self.max_pool3(x)\n",
    "        x = self.a4(x)\n",
    "        x = self.b4(x)\n",
    "        x = self.c4(x)\n",
    "        x = self.d4(x)\n",
    "        x = self.e4(x)\n",
    "        # x = self.max_pool4(x)\n",
    "        x = self.a5(x)\n",
    "        x = self.b5(x)\n",
    "        x = self.avg_pool(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 模型训练与评估类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timer(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start = time.time()\n",
    "        func(*args,**kwargs)\n",
    "        end = time.time()\n",
    "        cost = end - start\n",
    "        print(\"Cost time: {} mins.\".format(cost/60)) \n",
    "    return wrapper\n",
    "\n",
    "class CNNModel(object):\n",
    "    def __init__(self, model, train_data, test_data, model_dir, model_name,\n",
    "                 best_valid_loss=float('inf'), n_split=0.9, batch_size=64, epochs=10):\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.best_valid_loss = best_valid_loss\n",
    "        self.model_dir = model_dir\n",
    "        self.model_name = model_name\n",
    "        self.n_split = n_split\n",
    "        \n",
    "        self.train_data =  train_data\n",
    "        self.test_data = test_data\n",
    "        \n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.init_data()\n",
    "        self.init_iterator()\n",
    "        self.init_model_path()\n",
    "        \n",
    "        self.model = self.init_model(model)\n",
    "        self.optimizer = self.set_optimizer()\n",
    "        self.criterion = self.set_criterion()\n",
    "    \n",
    "    def init_data(self):\n",
    "        n_train = int(len(self.train_data)*self.n_split)\n",
    "        n_validation = len(self.train_data) - n_train\n",
    "        self.train_data, self.valid_data = torch.utils.data.random_split(self.train_data, [n_train, n_validation])\n",
    "    \n",
    "    def init_iterator(self):\n",
    "        self.train_iterator = torch.utils.data.DataLoader(self.train_data, shuffle=True, batch_size=self.batch_size)\n",
    "        self.valid_iterator = torch.utils.data.DataLoader(self.valid_data, batch_size=self.batch_size)\n",
    "        self.test_iterator = torch.utils.data.DataLoader(self.test_data, batch_size=self.batch_size)\n",
    "        \n",
    "    def set_optimizer(self):\n",
    "        optimizer = optim.Adam(self.model.parameters()) \n",
    "        return optimizer\n",
    "    \n",
    "    def set_criterion(self):\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        return criterion\n",
    "    \n",
    "    def init_model(self, model):\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            model = nn.DataParallel(model)\n",
    "        model = model.to(self.device)\n",
    "        return model\n",
    "        \n",
    "    def init_model_path(self):\n",
    "        if not os.path.isdir(self.model_dir):\n",
    "            os.makedirs(self.model_dir)\n",
    "        self.model_path = os.path.join(self.model_dir, self.model_name)\n",
    "        \n",
    "    # 定义评估函数\n",
    "    def accu(self, fx, y):\n",
    "        pred = fx.max(1,keepdim=True)[1]\n",
    "        correct = pred.eq(y.view_as(pred)).sum()  # 得到该batch的准确度\n",
    "        acc = correct.float()/pred.shape[0]\n",
    "        return acc\n",
    "\n",
    "    def train(self):\n",
    "        epoch_loss = 0   # 积累变量\n",
    "        epoch_acc = 0    # 积累变量\n",
    "        self.model.train()    # 该函数表示PHASE=Train\n",
    "\n",
    "        for (x,y) in self.train_iterator:  # 拿去每一个minibatch\n",
    "            x = x.to(self.device)\n",
    "            y = y.to(self.device)\n",
    "            self.optimizer.zero_grad()\n",
    "            fx = self.model(x)           # 进行forward\n",
    "            loss = self.criterion(fx,y)  # 计算Loss,train_loss\n",
    "            type(loss)\n",
    "            acc = self.accu(fx,y)      # 计算精确度，train_accu\n",
    "            loss.backward()     # 进行BP\n",
    "            self.optimizer.step()    # 统一更新模型\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "\n",
    "        return epoch_loss/len(self.train_iterator),epoch_acc/len(self.train_iterator)\n",
    "\n",
    "    def evaluate(self, iterator):\n",
    "        epoch_loss = 0\n",
    "        epoch_acc = 0\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for (x,y) in iterator:\n",
    "                x = x.to(self.device)\n",
    "                y = y.to(self.device)\n",
    "                fx = self.model(x)\n",
    "                loss = self.criterion(fx,y)\n",
    "                acc = self.accu(fx,y)\n",
    "                epoch_loss += loss.item()\n",
    "                epoch_acc += acc.item()\n",
    "        return epoch_loss/len(iterator),epoch_acc/len(iterator)\n",
    "    \n",
    "    @timer\n",
    "    def train_fit(self):\n",
    "        info = 'Epoch:{0} | Train Loss:{1} | Train Acc:{2} | Val Loss:{3} | Val Acc:{4}'\n",
    "        for epoch in range(self.epochs):\n",
    "            train_loss, train_acc = self.train()\n",
    "            valid_loss, valid_acc = self.evaluate(self.valid_iterator)\n",
    "            if valid_loss < self.best_valid_loss:  # 如果是最好的模型就保存到文件夹\n",
    "                self.best_valid_loss = valid_loss\n",
    "                torch.save(self.model.state_dict(), self.model_path)\n",
    "            print(info.format(epoch+1, train_loss, train_acc, valid_loss, valid_acc))\n",
    "    \n",
    "    def get_acc(self):\n",
    "        self.model.load_state_dict(torch.load(self.model_path))\n",
    "        test_loss, test_acc = self.evaluate(self.test_iterator)\n",
    "        print('| Test Loss: {0} | Test Acc: {1} |'.format(test_loss,test_acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 数据集的准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_trans = transforms.Compose([\n",
    "    transforms.Resize(32),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST('data', train=True, download=True, transform=data_trans)\n",
    "test_data = datasets.MNIST('data', train=False, download=True, transform=data_trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "n_split = 0.9\n",
    "batch_size = 64\n",
    "model_dir = 'models'\n",
    "best_valid_loss = float('inf')\n",
    "model_name = \"googlenet.pt\"\n",
    "model = GoogLeNet(in_channels=1,num_classes=10)\n",
    "\n",
    "obj = CNNModel(model=model, \n",
    "               train_data=train_data, \n",
    "               test_data=test_data, \n",
    "               model_dir=model_dir, \n",
    "               model_name=model_name,\n",
    "               best_valid_loss=best_valid_loss, \n",
    "               n_split=n_split, \n",
    "               batch_size=batch_size, \n",
    "               epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(obj.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataParallel(\n",
      "  (module): GoogLeNet(\n",
      "    (conv1): BasicConv2d(\n",
      "      (conv): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (max_pool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (conv2): BasicConv2d(\n",
      "      (conv): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (a3): Inception(\n",
      "      (branch1x1): BasicConv2d(\n",
      "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "      (branch3x3): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace)\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace)\n",
      "        )\n",
      "      )\n",
      "      (branch5x5): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace)\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace)\n",
      "        )\n",
      "      )\n",
      "      (branch_pool): Sequential(\n",
      "        (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (b3): Inception(\n",
      "      (branch1x1): BasicConv2d(\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "      (branch3x3): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace)\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace)\n",
      "        )\n",
      "      )\n",
      "      (branch5x5): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace)\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(32, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace)\n",
      "        )\n",
      "      )\n",
      "      (branch_pool): Sequential(\n",
      "        (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (max_pool3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (a4): Inception(\n",
      "      (branch1x1): BasicConv2d(\n",
      "        (conv): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "      (branch3x3): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace)\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(208, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace)\n",
      "        )\n",
      "      )\n",
      "      (branch5x5): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace)\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(16, 48, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "          (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace)\n",
      "        )\n",
      "      )\n",
      "      (branch_pool): Sequential(\n",
      "        (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (b4): Inception(\n",
      "      (branch1x1): BasicConv2d(\n",
      "        (conv): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "      (branch3x3): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace)\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace)\n",
      "        )\n",
      "      )\n",
      "      (branch5x5): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace)\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace)\n",
      "        )\n",
      "      )\n",
      "      (branch_pool): Sequential(\n",
      "        (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (c4): Inception(\n",
      "      (branch1x1): BasicConv2d(\n",
      "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "      (branch3x3): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace)\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace)\n",
      "        )\n",
      "      )\n",
      "      (branch5x5): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace)\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace)\n",
      "        )\n",
      "      )\n",
      "      (branch_pool): Sequential(\n",
      "        (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (d4): Inception(\n",
      "      (branch1x1): BasicConv2d(\n",
      "        (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "      (branch3x3): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace)\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace)\n",
      "        )\n",
      "      )\n",
      "      (branch5x5): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace)\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace)\n",
      "        )\n",
      "      )\n",
      "      (branch_pool): Sequential(\n",
      "        (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (e4): Inception(\n",
      "      (branch1x1): BasicConv2d(\n",
      "        (conv): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "      (branch3x3): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace)\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace)\n",
      "        )\n",
      "      )\n",
      "      (branch5x5): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace)\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace)\n",
      "        )\n",
      "      )\n",
      "      (branch_pool): Sequential(\n",
      "        (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (a5): Inception(\n",
      "      (branch1x1): BasicConv2d(\n",
      "        (conv): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "      (branch3x3): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace)\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace)\n",
      "        )\n",
      "      )\n",
      "      (branch5x5): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace)\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace)\n",
      "        )\n",
      "      )\n",
      "      (branch_pool): Sequential(\n",
      "        (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (b5): Inception(\n",
      "      (branch1x1): BasicConv2d(\n",
      "        (conv): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "      (branch3x3): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace)\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace)\n",
      "        )\n",
      "      )\n",
      "      (branch5x5): Sequential(\n",
      "        (0): BasicConv2d(\n",
      "          (conv): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace)\n",
      "        )\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(48, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace)\n",
      "        )\n",
      "      )\n",
      "      (branch_pool): Sequential(\n",
      "        (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "        (1): BasicConv2d(\n",
      "          (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (avg_pool): AvgPool2d(kernel_size=7, stride=7, padding=0)\n",
      "    (dropout): Dropout(p=0.4)\n",
      "    (classifier): Linear(in_features=1024, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(obj.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1 | Train Loss:0.20343272557473296 | Train Acc:0.9438129443127962 | Val Loss:0.0860832029002461 | Val Acc:0.9770057626227115\n",
      "Epoch:2 | Train Loss:0.07472551454485381 | Train Acc:0.9803700138466053 | Val Loss:0.055696024757591965 | Val Acc:0.9851507094312222\n",
      "Epoch:3 | Train Loss:0.056842647595507625 | Train Acc:0.9853006516587678 | Val Loss:0.04943874551657033 | Val Acc:0.9861480498567541\n",
      "Epoch:4 | Train Loss:0.04640269758382821 | Train Acc:0.987330914320539 | Val Loss:0.04173827684543868 | Val Acc:0.9894725179418604\n",
      "Epoch:5 | Train Loss:0.04042175161554059 | Train Acc:0.9891883886255924 | Val Loss:0.040216217998989875 | Val Acc:0.9876994680851063\n",
      "Epoch:6 | Train Loss:0.03700891847201398 | Train Acc:0.9899412519982641 | Val Loss:0.045699269768405465 | Val Acc:0.9877548763092528\n",
      "Epoch:7 | Train Loss:0.029438126076374787 | Train Acc:0.9917802132701422 | Val Loss:0.03431864774369813 | Val Acc:0.9896387413461157\n",
      "Epoch:8 | Train Loss:0.027639807626755105 | Train Acc:0.9926688388625592 | Val Loss:0.03561678497452646 | Val Acc:0.9898603723404256\n",
      "Epoch:9 | Train Loss:0.02521941594788319 | Train Acc:0.9930329285385484 | Val Loss:0.05354029526735874 | Val Acc:0.9848182626227115\n",
      "Epoch:10 | Train Loss:0.023476419649285516 | Train Acc:0.9932612559241706 | Val Loss:0.038400989085277344 | Val Acc:0.9893062945376051\n",
      "Epoch:11 | Train Loss:0.02259152984827033 | Train Acc:0.9935759774881516 | Val Loss:0.028426738822476028 | Val Acc:0.9931294328354775\n",
      "Epoch:12 | Train Loss:0.017678239814809114 | Train Acc:0.9951680983412322 | Val Loss:0.03715266724255808 | Val Acc:0.9906360817716476\n",
      "Epoch:13 | Train Loss:0.015991177308989437 | Train Acc:0.9951495853080569 | Val Loss:0.03849650760914417 | Val Acc:0.990802305175903\n",
      "Epoch:14 | Train Loss:0.013997699760335885 | Train Acc:0.9960752369668247 | Val Loss:0.035781646667523904 | Val Acc:0.9906914893617021\n",
      "Epoch:15 | Train Loss:0.015917640251258688 | Train Acc:0.9952976895734598 | Val Loss:0.034165637503239386 | Val Acc:0.9924645392184562\n",
      "Epoch:16 | Train Loss:0.012143293332534189 | Train Acc:0.9966861670616114 | Val Loss:0.038106602454989 | Val Acc:0.9913563829787234\n",
      "Epoch:17 | Train Loss:0.010415236477443416 | Train Acc:0.9971304798578199 | Val Loss:0.04065468463987271 | Val Acc:0.9899711881546264\n",
      "Epoch:18 | Train Loss:0.012013248926562685 | Train Acc:0.9967602191943128 | Val Loss:0.03539869956442457 | Val Acc:0.9921875\n",
      "Epoch:19 | Train Loss:0.010392529378520707 | Train Acc:0.9968342713270142 | Val Loss:0.03633220467367829 | Val Acc:0.9903590425531915\n",
      "Epoch:20 | Train Loss:0.010140876631908753 | Train Acc:0.9972415580568721 | Val Loss:0.026428732812959464 | Val Acc:0.9937943264524988\n",
      "Cost time: 53.23010371128718 mins.\n"
     ]
    }
   ],
   "source": [
    "obj.train_fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 0.026469486231684304 | Test Acc: 0.9940286624203821 |\n"
     ]
    }
   ],
   "source": [
    "obj.get_acc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
