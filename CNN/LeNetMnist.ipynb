{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Pytorch中神经网络模块化接口nn的了解:\n",
    "\n",
    "torch.nn是专门为神经网络设计的模块化接口。nn构建于autograd之上，可以用来定义和运行神经网络。\n",
    "nn.Module是nn中十分重要的类,包含网络各层的定义及forward方法。\n",
    "定义自已的网络：\n",
    "    需要继承nn.Module类，并实现forward方法。\n",
    "    一般把网络中具有可学习参数的层放在构造函数__init__()中，\n",
    "    不具有可学习参数的层(如ReLU)可放在构造函数中，也可不放在构造函数中(而在forward中使用nn.functional来代替)\n",
    "    \n",
    "    只要在nn.Module的子类中定义了forward函数，backward函数就会被自动实现(利用Autograd)。\n",
    "    在forward函数中可以使用任何Variable支持的函数，毕竟在整个pytorch构建的图中，是Variable在流动。还可以使用\n",
    "    if,for,print,log等python语法.\n",
    "    \n",
    "    注：Pytorch基于nn.Module构建的模型中，只支持mini-batch的Variable输入方式，\n",
    "    比如，只有一张输入图片，也需要变成 N x C x H x W 的形式：\n",
    "    \n",
    "    input_image = torch.FloatTensor(1, 28, 28)\n",
    "    input_image = Variable(input_image)\n",
    "    input_image = input_image.unsqueeze(0)   # 1 x 1 x 28 x 28\n",
    "\"\"\"\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        # nn.Module的子类函数必须在构造函数中执行父类的构造函数\n",
    "        super(LeNet, self).__init__()\n",
    "        # nn.Conv2d返回的是一个Conv2d class的一个对象，该类中包含forward函数的实现\n",
    "        # 当调用self.conv1(input)的时候，就会调用该类的forward函数\n",
    "        # 第一层conv1卷积层，in_channel=1,output_channel=6,kernel_size=5*5,input_size=32*32,output_size=28*28\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        # 第二层conv2，output_channel=6, kernel 5*5, output_size=10*10,input_size=14*14\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 80)\n",
    "        self.fc3 = nn.Linear(80, 10) # 不用增加softmax层，在cross_entropy的Loss中自动增加了Softmax\n",
    "       \n",
    "    # 定义了每次执行的 计算步骤。在所有的子类中都需要重写这个函数\n",
    "    def forward(self,x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)   # F.max_pool2d的返回值是一个Variable\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(x.shape[0], -1)  #？\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 模型训练与评估类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timer(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start = time.time()\n",
    "        func(*args,**kwargs)\n",
    "        end = time.time()\n",
    "        cost = end - start\n",
    "        print(\"Cost time: {} mins.\".format(cost/60)) \n",
    "    return wrapper\n",
    "\n",
    "class CNNModel(object):\n",
    "    def __init__(self, model, train_data, test_data, model_dir, model_name,\n",
    "                 best_valid_loss=float('inf'), n_split=0.9, batch_size=64, epochs=10):\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.best_valid_loss = best_valid_loss\n",
    "        self.model_dir = model_dir\n",
    "        self.model_name = model_name\n",
    "        self.n_split = n_split\n",
    "        \n",
    "        self.train_data =  train_data\n",
    "        self.test_data = test_data\n",
    "        \n",
    "        self.device = self.get_device()\n",
    "        self.init_data()\n",
    "        self.init_iterator()\n",
    "        self.init_model_path()\n",
    "        \n",
    "        self.model = self.init_model(model)\n",
    "        self.optimizer = self.set_optimizer()\n",
    "        self.criterion = self.set_criterion()\n",
    "        \n",
    "    def get_device(self):\n",
    "        d = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        return d\n",
    "    \n",
    "    def init_data(self):\n",
    "        n_train = int(len(self.train_data)*self.n_split)\n",
    "        n_validation = len(self.train_data) - n_train\n",
    "        self.train_data, self.valid_data = torch.utils.data.random_split(self.train_data, [n_train, n_validation])\n",
    "    \n",
    "    def init_iterator(self):\n",
    "        self.train_iterator = torch.utils.data.DataLoader(self.train_data, shuffle=True, batch_size=self.batch_size)\n",
    "        self.valid_iterator = torch.utils.data.DataLoader(self.valid_data, batch_size=self.batch_size)\n",
    "        self.test_iterator = torch.utils.data.DataLoader(self.test_data, batch_size=self.batch_size)\n",
    "        \n",
    "    def set_optimizer(self):\n",
    "        optimizer = optim.Adam(self.model.parameters()) \n",
    "        return optimizer\n",
    "    \n",
    "    def set_criterion(self):\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        return criterion\n",
    "    \n",
    "    def init_model(self, model):\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            model = nn.DataParallel(model)\n",
    "        model = model.to(self.device)\n",
    "        return model\n",
    "        \n",
    "    def init_model_path(self):\n",
    "        if not os.path.isdir(self.model_dir):\n",
    "            os.makedirs(self.model_dir)\n",
    "        self.model_path = os.path.join(self.model_dir, self.model_name)\n",
    "        \n",
    "    # 定义评估函数\n",
    "    def accu(self, fx, y):\n",
    "        pred = fx.max(1, keepdim=True)[1]\n",
    "        correct = pred.eq(y.view_as(pred)).sum()  # 得到该batch的准确度\n",
    "        acc = correct.float()/pred.shape[0]\n",
    "        return acc\n",
    "\n",
    "    def train(self):\n",
    "        epoch_loss = 0   # 积累变量\n",
    "        epoch_acc = 0    # 积累变量\n",
    "        self.model.train()    # 该函数表示PHASE=Train\n",
    "\n",
    "        for (x,y) in self.train_iterator:  # 拿去每一个minibatch\n",
    "            x = x.to(self.device)\n",
    "            y = y.to(self.device)\n",
    "            self.optimizer.zero_grad()\n",
    "            fx = self.model(x)           # 进行forward\n",
    "            loss = self.criterion(fx,y)  # 计算Loss,train_loss\n",
    "            type(loss)\n",
    "            acc = self.accu(fx,y)    # 计算精确度，train_accu\n",
    "            loss.backward()          # 进行BP\n",
    "            self.optimizer.step()    # 统一更新模型\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "\n",
    "        return epoch_loss/len(self.train_iterator),epoch_acc/len(self.train_iterator)\n",
    "\n",
    "    def evaluate(self, iterator):\n",
    "        epoch_loss = 0\n",
    "        epoch_acc = 0\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for (x,y) in iterator:\n",
    "                x = x.to(self.device)\n",
    "                y = y.to(self.device)\n",
    "                fx = self.model(x)\n",
    "                loss = self.criterion(fx,y)\n",
    "                acc = self.accu(fx,y)\n",
    "                epoch_loss += loss.item()\n",
    "                epoch_acc += acc.item()\n",
    "        return epoch_loss/len(iterator),epoch_acc/len(iterator)\n",
    "    \n",
    "    @timer\n",
    "    def train_fit(self):\n",
    "        info = 'Epoch:{0} | Train Loss:{1} | Train Acc:{2} | Val Loss:{3} | Val Acc:{4}'\n",
    "        for epoch in range(self.epochs):\n",
    "            train_loss, train_acc = self.train()\n",
    "            valid_loss, valid_acc = self.evaluate(self.valid_iterator)\n",
    "            if valid_loss < self.best_valid_loss:  # 如果是最好的模型就保存到文件夹\n",
    "                self.best_valid_loss = valid_loss\n",
    "                torch.save(self.model.state_dict(), self.model_path)\n",
    "            print(info.format(epoch+1, train_loss, train_acc, valid_loss, valid_acc))\n",
    "    \n",
    "    def get_acc(self):\n",
    "        self.model.load_state_dict(torch.load(self.model_path))\n",
    "        test_loss, test_acc = self.evaluate(self.test_iterator)\n",
    "        print('| Test Loss: {0} | Test Acc: {1} |'.format(test_loss,test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: conv1.weight, param: Parameter containing:\n",
      "tensor([[[[-0.1873,  0.0293,  0.1334, -0.1339,  0.0741],\n",
      "          [ 0.1257, -0.0284, -0.0870,  0.1061, -0.1750],\n",
      "          [ 0.1333, -0.1818,  0.1927, -0.0793,  0.0738],\n",
      "          [ 0.0105, -0.0376,  0.0436, -0.1772, -0.1445],\n",
      "          [-0.1396, -0.1077,  0.1500,  0.0755,  0.1046]]],\n",
      "\n",
      "\n",
      "        [[[-0.1844,  0.0790, -0.1209,  0.0697, -0.0633],\n",
      "          [ 0.0694, -0.1453, -0.0114, -0.0374,  0.1901],\n",
      "          [-0.0468, -0.0940, -0.1349, -0.1380,  0.0994],\n",
      "          [-0.1889,  0.1676,  0.0982,  0.1877, -0.0283],\n",
      "          [ 0.1947,  0.0166, -0.1786,  0.0401,  0.1431]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0616, -0.1101,  0.0804,  0.1234, -0.0296],\n",
      "          [-0.1817, -0.0150, -0.1269, -0.1712,  0.0769],\n",
      "          [ 0.1827,  0.1125, -0.0730,  0.0531, -0.0166],\n",
      "          [ 0.0919,  0.0516,  0.1305,  0.0809,  0.1155],\n",
      "          [-0.0563, -0.1623,  0.1143,  0.0820, -0.0788]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1474,  0.1437, -0.0107, -0.1228,  0.0898],\n",
      "          [ 0.1468,  0.1188, -0.1526, -0.1080, -0.0449],\n",
      "          [-0.0770, -0.0976,  0.0749,  0.1082,  0.0134],\n",
      "          [ 0.0650, -0.0098,  0.1680,  0.0662, -0.0055],\n",
      "          [ 0.1481, -0.0926, -0.1987,  0.1166, -0.1031]]],\n",
      "\n",
      "\n",
      "        [[[-0.1697,  0.1116,  0.1161,  0.0322, -0.1921],\n",
      "          [-0.1251,  0.0760, -0.1094,  0.1704,  0.1477],\n",
      "          [-0.1355,  0.0818, -0.1011, -0.1638,  0.1288],\n",
      "          [-0.0923, -0.0807,  0.0551, -0.0213, -0.1339],\n",
      "          [-0.1127, -0.0727,  0.1566, -0.0573,  0.1143]]],\n",
      "\n",
      "\n",
      "        [[[-0.0085,  0.1824,  0.1666, -0.0882, -0.1635],\n",
      "          [-0.1942,  0.0613,  0.0225,  0.1933, -0.0596],\n",
      "          [-0.1719, -0.0760, -0.1209, -0.1026,  0.0261],\n",
      "          [-0.0369, -0.0522,  0.0065,  0.0277,  0.1126],\n",
      "          [-0.1868,  0.1849,  0.1788, -0.1621, -0.0119]]]], requires_grad=True)\n",
      "name: conv1.bias, param: Parameter containing:\n",
      "tensor([-0.0072, -0.1810,  0.1319, -0.1359, -0.1000,  0.0510],\n",
      "       requires_grad=True)\n",
      "name: conv2.weight, param: Parameter containing:\n",
      "tensor([[[[ 0.0707, -0.0467, -0.0792,  0.0108, -0.0609],\n",
      "          [-0.0626,  0.0260, -0.0528,  0.0688, -0.0425],\n",
      "          [-0.0077,  0.0760, -0.0680, -0.0427, -0.0141],\n",
      "          [ 0.0372,  0.0564,  0.0486,  0.0594,  0.0261],\n",
      "          [-0.0503,  0.0316,  0.0385, -0.0425,  0.0328]],\n",
      "\n",
      "         [[-0.0548, -0.0814,  0.0494,  0.0505, -0.0387],\n",
      "          [-0.0401,  0.0116, -0.0765,  0.0647, -0.0600],\n",
      "          [-0.0772,  0.0488, -0.0651, -0.0433, -0.0534],\n",
      "          [-0.0592, -0.0572,  0.0683,  0.0665,  0.0108],\n",
      "          [-0.0397, -0.0501, -0.0375,  0.0483,  0.0746]],\n",
      "\n",
      "         [[-0.0745, -0.0345, -0.0584,  0.0340, -0.0680],\n",
      "          [-0.0478,  0.0233,  0.0410, -0.0194,  0.0394],\n",
      "          [-0.0010, -0.0033,  0.0177, -0.0308,  0.0179],\n",
      "          [-0.0685, -0.0737, -0.0034,  0.0278, -0.0757],\n",
      "          [-0.0798, -0.0328, -0.0215,  0.0075, -0.0741]],\n",
      "\n",
      "         [[-0.0512,  0.0040,  0.0153,  0.0495,  0.0281],\n",
      "          [-0.0332,  0.0785,  0.0679,  0.0493,  0.0179],\n",
      "          [ 0.0185, -0.0048,  0.0216, -0.0375, -0.0715],\n",
      "          [ 0.0485,  0.0183,  0.0579, -0.0074,  0.0223],\n",
      "          [-0.0281,  0.0013, -0.0166, -0.0139,  0.0214]],\n",
      "\n",
      "         [[-0.0577, -0.0146,  0.0060,  0.0111, -0.0653],\n",
      "          [-0.0652, -0.0040, -0.0785,  0.0710,  0.0436],\n",
      "          [-0.0378,  0.0070,  0.0297,  0.0667,  0.0799],\n",
      "          [ 0.0118, -0.0762,  0.0750,  0.0707,  0.0023],\n",
      "          [-0.0250,  0.0325,  0.0555,  0.0053, -0.0440]],\n",
      "\n",
      "         [[ 0.0525,  0.0172, -0.0324, -0.0184, -0.0097],\n",
      "          [ 0.0164, -0.0039,  0.0721,  0.0468, -0.0553],\n",
      "          [ 0.0160,  0.0353,  0.0121,  0.0394, -0.0733],\n",
      "          [ 0.0436, -0.0294,  0.0145, -0.0050,  0.0725],\n",
      "          [ 0.0741,  0.0323,  0.0137, -0.0123, -0.0029]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0191,  0.0244, -0.0449, -0.0054, -0.0804],\n",
      "          [ 0.0390,  0.0016,  0.0217, -0.0025, -0.0803],\n",
      "          [ 0.0767,  0.0663,  0.0521,  0.0212, -0.0250],\n",
      "          [ 0.0530,  0.0570, -0.0384, -0.0115,  0.0708],\n",
      "          [ 0.0094,  0.0349, -0.0372, -0.0246, -0.0593]],\n",
      "\n",
      "         [[ 0.0731, -0.0426, -0.0778, -0.0033, -0.0364],\n",
      "          [-0.0718,  0.0667, -0.0444, -0.0186, -0.0183],\n",
      "          [ 0.0056, -0.0086,  0.0270,  0.0645,  0.0740],\n",
      "          [-0.0767, -0.0548, -0.0294,  0.0031, -0.0011],\n",
      "          [ 0.0294, -0.0393, -0.0183,  0.0036, -0.0785]],\n",
      "\n",
      "         [[-0.0096, -0.0470,  0.0679, -0.0153, -0.0371],\n",
      "          [ 0.0164, -0.0438, -0.0777, -0.0473, -0.0625],\n",
      "          [ 0.0321, -0.0182, -0.0373,  0.0586, -0.0326],\n",
      "          [ 0.0379,  0.0379, -0.0280,  0.0529, -0.0380],\n",
      "          [-0.0185,  0.0703, -0.0617,  0.0579, -0.0688]],\n",
      "\n",
      "         [[-0.0038,  0.0686, -0.0633,  0.0057,  0.0668],\n",
      "          [ 0.0540,  0.0409, -0.0412,  0.0011,  0.0550],\n",
      "          [-0.0360,  0.0345,  0.0728, -0.0187,  0.0354],\n",
      "          [-0.0451, -0.0039,  0.0445,  0.0108, -0.0351],\n",
      "          [ 0.0634, -0.0622,  0.0010, -0.0005,  0.0584]],\n",
      "\n",
      "         [[-0.0176, -0.0014,  0.0561, -0.0587,  0.0435],\n",
      "          [-0.0465, -0.0481, -0.0555, -0.0746,  0.0704],\n",
      "          [-0.0426,  0.0759,  0.0126, -0.0810, -0.0330],\n",
      "          [ 0.0231,  0.0403, -0.0366,  0.0532, -0.0570],\n",
      "          [ 0.0037, -0.0271,  0.0424, -0.0703,  0.0213]],\n",
      "\n",
      "         [[ 0.0815, -0.0599, -0.0600, -0.0422,  0.0108],\n",
      "          [ 0.0650,  0.0774, -0.0341, -0.0393,  0.0127],\n",
      "          [ 0.0068, -0.0773, -0.0261,  0.0676,  0.0781],\n",
      "          [-0.0406,  0.0731, -0.0211, -0.0040,  0.0516],\n",
      "          [ 0.0490,  0.0338,  0.0020, -0.0416, -0.0373]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0657,  0.0506, -0.0455, -0.0522, -0.0713],\n",
      "          [ 0.0360, -0.0234,  0.0618, -0.0631, -0.0282],\n",
      "          [ 0.0440, -0.0763,  0.0160, -0.0689, -0.0656],\n",
      "          [-0.0611, -0.0486, -0.0778, -0.0540,  0.0623],\n",
      "          [ 0.0816,  0.0135, -0.0682,  0.0528, -0.0490]],\n",
      "\n",
      "         [[-0.0798,  0.0174, -0.0064, -0.0593, -0.0425],\n",
      "          [-0.0176, -0.0723,  0.0649,  0.0608,  0.0371],\n",
      "          [-0.0145,  0.0009, -0.0532,  0.0316, -0.0176],\n",
      "          [ 0.0359,  0.0075,  0.0803,  0.0477,  0.0397],\n",
      "          [-0.0693,  0.0163,  0.0191, -0.0499, -0.0532]],\n",
      "\n",
      "         [[-0.0589,  0.0346, -0.0032, -0.0676,  0.0383],\n",
      "          [-0.0039,  0.0808,  0.0681, -0.0175,  0.0293],\n",
      "          [-0.0513, -0.0562, -0.0533, -0.0217,  0.0176],\n",
      "          [-0.0724, -0.0077, -0.0293,  0.0803, -0.0131],\n",
      "          [ 0.0410,  0.0023,  0.0505,  0.0442, -0.0657]],\n",
      "\n",
      "         [[-0.0493, -0.0397,  0.0395,  0.0815,  0.0478],\n",
      "          [-0.0030, -0.0430,  0.0378,  0.0617, -0.0399],\n",
      "          [ 0.0039,  0.0498,  0.0601, -0.0419,  0.0355],\n",
      "          [-0.0645,  0.0249,  0.0311,  0.0677,  0.0692],\n",
      "          [-0.0456, -0.0187, -0.0390,  0.0484, -0.0334]],\n",
      "\n",
      "         [[-0.0462,  0.0244,  0.0215, -0.0424,  0.0327],\n",
      "          [-0.0140,  0.0444, -0.0620, -0.0071, -0.0772],\n",
      "          [-0.0606, -0.0211, -0.0602,  0.0505, -0.0567],\n",
      "          [ 0.0750,  0.0101, -0.0273, -0.0647,  0.0775],\n",
      "          [-0.0249, -0.0330, -0.0637,  0.0607, -0.0719]],\n",
      "\n",
      "         [[-0.0516, -0.0533,  0.0075, -0.0007, -0.0329],\n",
      "          [-0.0222, -0.0285,  0.0769, -0.0668, -0.0170],\n",
      "          [-0.0205, -0.0450,  0.0662, -0.0779, -0.0657],\n",
      "          [-0.0539, -0.0569,  0.0672,  0.0101,  0.0712],\n",
      "          [-0.0310, -0.0061,  0.0605,  0.0551, -0.0783]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0439, -0.0427, -0.0093, -0.0159,  0.0197],\n",
      "          [ 0.0112, -0.0570,  0.0628,  0.0408, -0.0273],\n",
      "          [-0.0149,  0.0103,  0.0510,  0.0513, -0.0530],\n",
      "          [ 0.0673,  0.0559,  0.0662,  0.0746, -0.0791],\n",
      "          [ 0.0463, -0.0626, -0.0303, -0.0291, -0.0076]],\n",
      "\n",
      "         [[-0.0346, -0.0672,  0.0636,  0.0693,  0.0303],\n",
      "          [-0.0414, -0.0347,  0.0628, -0.0618, -0.0245],\n",
      "          [-0.0230, -0.0304, -0.0608, -0.0689,  0.0227],\n",
      "          [ 0.0184,  0.0421, -0.0753, -0.0328, -0.0441],\n",
      "          [-0.0013,  0.0371, -0.0410,  0.0206, -0.0812]],\n",
      "\n",
      "         [[-0.0464, -0.0438, -0.0222,  0.0129, -0.0066],\n",
      "          [-0.0310,  0.0441, -0.0569, -0.0334,  0.0310],\n",
      "          [ 0.0072, -0.0042,  0.0222, -0.0503,  0.0558],\n",
      "          [-0.0324, -0.0211, -0.0261,  0.0645, -0.0269],\n",
      "          [-0.0224,  0.0769, -0.0451, -0.0302, -0.0434]],\n",
      "\n",
      "         [[ 0.0050,  0.0237,  0.0226,  0.0029,  0.0647],\n",
      "          [-0.0311,  0.0091, -0.0049,  0.0059, -0.0665],\n",
      "          [-0.0772,  0.0472,  0.0727,  0.0660, -0.0679],\n",
      "          [-0.0351,  0.0278,  0.0225, -0.0011, -0.0045],\n",
      "          [-0.0045,  0.0069, -0.0023, -0.0546, -0.0156]],\n",
      "\n",
      "         [[-0.0192, -0.0209, -0.0218, -0.0387, -0.0200],\n",
      "          [-0.0735, -0.0356, -0.0447,  0.0305,  0.0470],\n",
      "          [ 0.0131, -0.0130,  0.0219,  0.0262,  0.0220],\n",
      "          [ 0.0338, -0.0581,  0.0284, -0.0799,  0.0424],\n",
      "          [-0.0225, -0.0279, -0.0105, -0.0084, -0.0490]],\n",
      "\n",
      "         [[ 0.0474, -0.0749,  0.0066, -0.0616, -0.0806],\n",
      "          [ 0.0066,  0.0038, -0.0276, -0.0531, -0.0148],\n",
      "          [ 0.0181, -0.0241, -0.0293, -0.0585, -0.0222],\n",
      "          [-0.0419,  0.0609, -0.0555, -0.0111,  0.0033],\n",
      "          [-0.0683, -0.0117,  0.0031, -0.0463,  0.0122]]],\n",
      "\n",
      "\n",
      "        [[[-0.0620, -0.0739, -0.0712, -0.0754,  0.0599],\n",
      "          [-0.0232, -0.0594, -0.0004,  0.0696,  0.0692],\n",
      "          [-0.0141,  0.0438, -0.0146, -0.0315,  0.0185],\n",
      "          [ 0.0127, -0.0029, -0.0020, -0.0139, -0.0338],\n",
      "          [-0.0561, -0.0633, -0.0510,  0.0281, -0.0008]],\n",
      "\n",
      "         [[ 0.0040,  0.0064,  0.0721,  0.0630, -0.0046],\n",
      "          [-0.0239, -0.0238, -0.0364,  0.0010,  0.0548],\n",
      "          [-0.0346, -0.0054,  0.0623,  0.0731,  0.0790],\n",
      "          [-0.0279, -0.0760, -0.0441, -0.0154, -0.0058],\n",
      "          [ 0.0156, -0.0316,  0.0252, -0.0452,  0.0700]],\n",
      "\n",
      "         [[ 0.0663,  0.0015,  0.0727,  0.0457,  0.0415],\n",
      "          [ 0.0134, -0.0442, -0.0039, -0.0692, -0.0791],\n",
      "          [-0.0522,  0.0796, -0.0085, -0.0237, -0.0597],\n",
      "          [-0.0730, -0.0140,  0.0146, -0.0789,  0.0556],\n",
      "          [ 0.0636, -0.0201, -0.0538,  0.0736,  0.0401]],\n",
      "\n",
      "         [[ 0.0261, -0.0463,  0.0775,  0.0063, -0.0105],\n",
      "          [-0.0268, -0.0245, -0.0075,  0.0576, -0.0085],\n",
      "          [-0.0710, -0.0772, -0.0620,  0.0283, -0.0504],\n",
      "          [-0.0432, -0.0604,  0.0061, -0.0723,  0.0685],\n",
      "          [ 0.0680, -0.0774,  0.0796,  0.0006, -0.0141]],\n",
      "\n",
      "         [[-0.0334,  0.0127,  0.0311, -0.0047, -0.0300],\n",
      "          [ 0.0551, -0.0463, -0.0346, -0.0749, -0.0146],\n",
      "          [-0.0408,  0.0455, -0.0729, -0.0458,  0.0341],\n",
      "          [-0.0443, -0.0774,  0.0348,  0.0340, -0.0649],\n",
      "          [-0.0176, -0.0569, -0.0164,  0.0277,  0.0462]],\n",
      "\n",
      "         [[ 0.0619, -0.0629,  0.0293, -0.0785, -0.0759],\n",
      "          [ 0.0755,  0.0511,  0.0751, -0.0182, -0.0421],\n",
      "          [-0.0417,  0.0330, -0.0391, -0.0570,  0.0785],\n",
      "          [-0.0496, -0.0517, -0.0315,  0.0494, -0.0070],\n",
      "          [-0.0547,  0.0590,  0.0135, -0.0544,  0.0243]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0667, -0.0172,  0.0408,  0.0019, -0.0136],\n",
      "          [-0.0585,  0.0726,  0.0252, -0.0306, -0.0601],\n",
      "          [ 0.0367,  0.0066, -0.0261, -0.0274,  0.0639],\n",
      "          [-0.0254,  0.0766,  0.0700, -0.0141, -0.0521],\n",
      "          [-0.0006, -0.0441,  0.0143,  0.0048,  0.0534]],\n",
      "\n",
      "         [[-0.0636,  0.0343, -0.0427,  0.0360,  0.0190],\n",
      "          [ 0.0346,  0.0146,  0.0074, -0.0470,  0.0162],\n",
      "          [-0.0062,  0.0156,  0.0094, -0.0476, -0.0334],\n",
      "          [-0.0564,  0.0486, -0.0580,  0.0717, -0.0715],\n",
      "          [-0.0658,  0.0405,  0.0203, -0.0474, -0.0415]],\n",
      "\n",
      "         [[ 0.0719, -0.0744, -0.0498,  0.0592,  0.0037],\n",
      "          [-0.0272, -0.0436, -0.0311,  0.0148,  0.0254],\n",
      "          [-0.0226, -0.0083,  0.0600, -0.0123,  0.0800],\n",
      "          [ 0.0334, -0.0434,  0.0671,  0.0400,  0.0079],\n",
      "          [-0.0479, -0.0101, -0.0094, -0.0734,  0.0436]],\n",
      "\n",
      "         [[-0.0064, -0.0670, -0.0309, -0.0383,  0.0210],\n",
      "          [ 0.0244,  0.0461,  0.0278,  0.0210,  0.0701],\n",
      "          [ 0.0635, -0.0713, -0.0361,  0.0785, -0.0588],\n",
      "          [ 0.0611,  0.0676,  0.0796, -0.0147,  0.0027],\n",
      "          [-0.0564, -0.0286, -0.0104, -0.0133, -0.0339]],\n",
      "\n",
      "         [[ 0.0080,  0.0680,  0.0430, -0.0105,  0.0022],\n",
      "          [ 0.0168, -0.0600,  0.0019, -0.0158, -0.0056],\n",
      "          [ 0.0170,  0.0477,  0.0684, -0.0798, -0.0120],\n",
      "          [-0.0717,  0.0460, -0.0544, -0.0412,  0.0617],\n",
      "          [ 0.0127, -0.0339, -0.0061,  0.0460,  0.0409]],\n",
      "\n",
      "         [[ 0.0769, -0.0698,  0.0058,  0.0172,  0.0776],\n",
      "          [-0.0036,  0.0401, -0.0205, -0.0298,  0.0238],\n",
      "          [-0.0168,  0.0666,  0.0213,  0.0264,  0.0425],\n",
      "          [-0.0342, -0.0309, -0.0648, -0.0548, -0.0452],\n",
      "          [ 0.0045, -0.0101,  0.0200, -0.0808, -0.0564]]]], requires_grad=True)\n",
      "name: conv2.bias, param: Parameter containing:\n",
      "tensor([ 0.0173, -0.0279,  0.0176,  0.0157, -0.0205,  0.0480,  0.0356, -0.0667,\n",
      "        -0.0039, -0.0753, -0.0071,  0.0083,  0.0604,  0.0420,  0.0442, -0.0227],\n",
      "       requires_grad=True)\n",
      "name: fc1.weight, param: Parameter containing:\n",
      "tensor([[-0.0386, -0.0373, -0.0241,  ..., -0.0084, -0.0319, -0.0261],\n",
      "        [-0.0247, -0.0311, -0.0163,  ..., -0.0253, -0.0243,  0.0276],\n",
      "        [ 0.0411, -0.0243, -0.0159,  ..., -0.0398, -0.0052, -0.0326],\n",
      "        ...,\n",
      "        [ 0.0069,  0.0276,  0.0365,  ..., -0.0193, -0.0441, -0.0079],\n",
      "        [ 0.0498,  0.0244,  0.0451,  ...,  0.0378, -0.0198, -0.0388],\n",
      "        [ 0.0344,  0.0002, -0.0363,  ...,  0.0312,  0.0196,  0.0133]],\n",
      "       requires_grad=True)\n",
      "name: fc1.bias, param: Parameter containing:\n",
      "tensor([ 0.0312,  0.0082,  0.0366,  0.0314,  0.0007, -0.0379,  0.0330,  0.0170,\n",
      "        -0.0074, -0.0418, -0.0140, -0.0287,  0.0177, -0.0113, -0.0346,  0.0277,\n",
      "        -0.0357,  0.0045, -0.0181,  0.0026, -0.0472, -0.0117, -0.0033,  0.0423,\n",
      "         0.0257, -0.0068,  0.0177, -0.0305, -0.0122, -0.0041, -0.0412, -0.0355,\n",
      "        -0.0480, -0.0048,  0.0091, -0.0454, -0.0004, -0.0058, -0.0160, -0.0119,\n",
      "        -0.0290, -0.0069, -0.0112,  0.0056,  0.0072, -0.0312,  0.0149,  0.0468,\n",
      "         0.0133,  0.0334,  0.0010,  0.0303,  0.0138,  0.0097,  0.0471, -0.0114,\n",
      "        -0.0388, -0.0431, -0.0122,  0.0165, -0.0172,  0.0417, -0.0231,  0.0481,\n",
      "        -0.0374, -0.0159,  0.0050, -0.0263, -0.0123, -0.0306, -0.0387, -0.0083,\n",
      "        -0.0344, -0.0323,  0.0243,  0.0302,  0.0107,  0.0303,  0.0030, -0.0087,\n",
      "        -0.0374,  0.0486, -0.0101,  0.0335, -0.0220, -0.0336,  0.0040,  0.0346,\n",
      "         0.0155, -0.0258, -0.0259,  0.0437, -0.0057,  0.0446,  0.0018, -0.0275,\n",
      "        -0.0397, -0.0365, -0.0099, -0.0395, -0.0060,  0.0391,  0.0058,  0.0459,\n",
      "        -0.0399,  0.0304,  0.0079, -0.0093,  0.0497,  0.0202,  0.0166, -0.0472,\n",
      "         0.0457, -0.0079,  0.0227, -0.0411, -0.0427,  0.0074, -0.0085,  0.0139],\n",
      "       requires_grad=True)\n",
      "name: fc2.weight, param: Parameter containing:\n",
      "tensor([[-0.0842, -0.0315, -0.0206,  ..., -0.0368,  0.0716, -0.0097],\n",
      "        [ 0.0495, -0.0164,  0.0734,  ...,  0.0087, -0.0895,  0.0131],\n",
      "        [-0.0742,  0.0243,  0.0707,  ...,  0.0545, -0.0197,  0.0059],\n",
      "        ...,\n",
      "        [-0.0121,  0.0390, -0.0725,  ...,  0.0455,  0.0412, -0.0509],\n",
      "        [ 0.0124,  0.0675,  0.0571,  ..., -0.0517,  0.0788, -0.0027],\n",
      "        [ 0.0682, -0.0125,  0.0329,  ..., -0.0163, -0.0258, -0.0048]],\n",
      "       requires_grad=True)\n",
      "name: fc2.bias, param: Parameter containing:\n",
      "tensor([-0.0549,  0.0639, -0.0805, -0.0473,  0.0269, -0.0632,  0.0810, -0.0348,\n",
      "        -0.0359, -0.0671,  0.0281, -0.0415,  0.0289, -0.0383,  0.0240, -0.0809,\n",
      "         0.0089,  0.0798, -0.0304, -0.0030, -0.0478, -0.0708, -0.0262,  0.0591,\n",
      "        -0.0029, -0.0480, -0.0440, -0.0110, -0.0164, -0.0288, -0.0355,  0.0761,\n",
      "        -0.0439, -0.0404,  0.0621, -0.0219,  0.0340,  0.0520, -0.0550, -0.0426,\n",
      "         0.0682, -0.0219,  0.0905,  0.0339, -0.0267, -0.0663,  0.0800,  0.0187,\n",
      "        -0.0410,  0.0073, -0.0408,  0.0135, -0.0478, -0.0323,  0.0211,  0.0801,\n",
      "         0.0773, -0.0741, -0.0746,  0.0622,  0.0039,  0.0237,  0.0575,  0.0902,\n",
      "         0.0398, -0.0294,  0.0724, -0.0253, -0.0443, -0.0843, -0.0055, -0.0758,\n",
      "        -0.0031, -0.0385,  0.0413, -0.0452,  0.0505, -0.0637,  0.0249,  0.0553],\n",
      "       requires_grad=True)\n",
      "name: fc3.weight, param: Parameter containing:\n",
      "tensor([[ 2.2402e-02, -3.5252e-02,  4.8266e-02, -7.9652e-02,  4.1704e-02,\n",
      "          8.8430e-02, -9.0894e-02,  1.4062e-02,  9.1516e-02, -3.7116e-02,\n",
      "          5.1777e-02, -7.0332e-02,  8.9548e-02, -1.0893e-01, -2.7865e-03,\n",
      "         -3.0494e-02, -3.2755e-02,  2.7425e-02, -4.8576e-02, -5.2972e-02,\n",
      "          9.9092e-02, -9.4260e-03,  2.4947e-02,  1.9377e-02,  1.7215e-03,\n",
      "         -5.8770e-02, -6.5988e-02,  2.5407e-02,  1.3683e-02,  9.0047e-02,\n",
      "         -7.2404e-02,  5.4867e-02, -7.7927e-02,  5.3228e-02, -2.2118e-02,\n",
      "          3.2006e-02,  6.0612e-02,  3.1892e-02, -3.8419e-02, -1.3777e-02,\n",
      "          9.4387e-02, -6.4565e-02, -7.5126e-02,  2.2328e-02, -5.4918e-02,\n",
      "          4.2580e-02, -1.2588e-03,  7.4093e-02, -6.8332e-02,  9.5796e-02,\n",
      "         -2.9493e-02, -7.2052e-02, -1.1141e-01,  1.0114e-01,  4.8681e-02,\n",
      "         -4.0207e-02, -2.2972e-02, -2.1722e-02,  3.4281e-02,  3.8147e-02,\n",
      "          9.7463e-02,  5.8187e-02,  6.1759e-02,  1.5238e-02, -3.3686e-02,\n",
      "         -1.0838e-01, -8.2841e-02,  2.7130e-02, -3.3617e-02,  4.5287e-02,\n",
      "         -4.1436e-02, -9.3739e-02,  5.3140e-02, -9.6996e-02,  3.5190e-02,\n",
      "         -2.1408e-02,  5.9987e-02,  5.6908e-02, -2.9586e-02, -5.7593e-02],\n",
      "        [ 1.0603e-02,  5.1301e-02,  8.5957e-02,  1.0122e-01,  4.5210e-02,\n",
      "          9.0213e-02, -6.6672e-02,  2.0363e-02, -4.8871e-02,  8.5995e-02,\n",
      "         -8.7014e-03, -6.6853e-02,  4.4904e-02, -9.7627e-02, -6.8094e-02,\n",
      "         -3.2110e-02,  8.3341e-03,  1.0626e-02, -1.0540e-01, -9.7050e-02,\n",
      "         -2.4285e-02,  6.4007e-02, -6.2978e-03,  3.3274e-03, -6.2767e-02,\n",
      "         -4.0757e-02, -8.6051e-02, -5.4676e-02, -3.1288e-02,  3.1144e-02,\n",
      "          4.4851e-03, -9.6979e-02,  3.3271e-02,  1.4158e-02,  5.0377e-02,\n",
      "         -6.9978e-02,  3.5713e-02,  1.0830e-01, -3.4003e-02, -1.1013e-01,\n",
      "         -5.4203e-02,  8.0178e-02, -1.3813e-02,  1.5927e-02,  2.0586e-02,\n",
      "          2.8361e-02, -3.6237e-02, -1.2035e-02, -1.0368e-01,  1.1058e-01,\n",
      "          8.0389e-03, -8.4111e-02,  4.6304e-02, -8.3882e-03, -8.8200e-02,\n",
      "          3.5842e-02, -7.6190e-02,  7.7718e-02,  5.3604e-02,  9.1089e-02,\n",
      "         -1.2040e-02,  1.0201e-02, -4.7756e-02, -8.1074e-02,  7.9546e-02,\n",
      "          3.7279e-02, -8.6647e-02, -1.0842e-01,  1.0809e-01, -3.5233e-02,\n",
      "         -6.0825e-02,  1.0851e-01,  1.3419e-03, -3.8087e-02, -3.5809e-02,\n",
      "          3.5811e-02,  3.6314e-02, -7.9241e-02, -1.0523e-02,  1.6139e-02],\n",
      "        [-7.5362e-02, -5.3136e-02,  4.2147e-02,  7.3522e-02,  8.4562e-02,\n",
      "          1.1061e-01,  7.8259e-02, -2.8577e-02, -6.2578e-02,  5.6050e-02,\n",
      "         -6.8513e-02, -7.3586e-02,  6.1689e-02,  9.9598e-02,  9.4445e-03,\n",
      "         -1.0387e-01, -7.9136e-02, -6.0700e-02,  3.2638e-02,  7.5561e-02,\n",
      "          2.7989e-02,  7.4970e-02, -1.1060e-01,  2.2520e-03,  3.3557e-02,\n",
      "          1.1708e-02,  7.5537e-02, -4.1327e-03,  9.7584e-02, -4.1002e-02,\n",
      "         -4.0799e-02,  9.4318e-02, -4.0579e-03,  7.0403e-02,  9.9915e-02,\n",
      "          2.4035e-02,  5.0109e-02,  1.0521e-01, -3.4822e-02,  8.2878e-02,\n",
      "         -3.7010e-02, -7.4658e-02, -8.2034e-03,  4.7561e-02, -5.7097e-02,\n",
      "          8.4142e-03, -8.3805e-02,  7.4029e-02,  3.4189e-02, -1.2851e-02,\n",
      "          6.5609e-02,  5.8696e-02,  1.0112e-01, -2.7243e-02, -9.1408e-02,\n",
      "          9.0336e-02,  1.0783e-01, -1.3046e-02,  9.0160e-02,  1.2862e-02,\n",
      "         -6.5988e-02, -1.0185e-01, -8.8181e-02,  6.3270e-02,  2.2210e-02,\n",
      "         -1.3770e-02,  1.2771e-02,  3.3362e-02,  9.9768e-03,  6.2193e-02,\n",
      "         -3.0817e-02, -1.5174e-02,  3.1200e-02,  3.7768e-02,  3.6213e-02,\n",
      "          1.0146e-01,  5.6257e-02,  9.9956e-02,  3.2557e-02, -4.7602e-02],\n",
      "        [-1.2636e-02,  1.1049e-01,  6.0999e-02,  1.4613e-02,  4.3664e-02,\n",
      "          6.4983e-04,  6.9429e-02,  2.5955e-03,  6.7299e-02, -1.1175e-01,\n",
      "          3.0088e-02,  7.1033e-02,  3.5226e-03,  8.0165e-02,  6.9514e-02,\n",
      "          5.9237e-02,  6.9617e-02,  7.9063e-02, -7.0141e-04, -4.6747e-02,\n",
      "          9.9997e-02, -3.6991e-02, -2.3423e-02, -1.6330e-02, -1.0855e-01,\n",
      "          5.9405e-02,  1.0016e-01,  2.1117e-02, -8.3528e-02, -1.0513e-01,\n",
      "         -2.3838e-02, -2.8596e-02, -6.4931e-02,  3.0123e-02,  7.6318e-02,\n",
      "         -8.3120e-02, -1.0587e-01, -8.5493e-02, -7.7234e-02, -1.6136e-02,\n",
      "         -8.3684e-02, -1.0598e-01, -7.2703e-02,  3.1059e-02,  3.5447e-03,\n",
      "          3.7976e-02,  2.5440e-02, -5.6039e-02, -7.6154e-02,  2.2058e-02,\n",
      "         -3.7353e-02, -7.1121e-02, -4.6102e-02, -7.0595e-02, -7.5958e-02,\n",
      "          5.5582e-03,  6.2004e-02, -5.6350e-02, -7.7934e-02,  2.0037e-02,\n",
      "         -2.6599e-02, -8.9755e-02, -1.0008e-01,  6.2142e-02, -9.8961e-02,\n",
      "         -2.1832e-02,  6.2847e-02, -9.5345e-02,  9.7416e-02, -1.1415e-02,\n",
      "         -8.6799e-02,  4.4099e-02, -3.6611e-02, -1.3201e-02,  1.9410e-02,\n",
      "         -6.1601e-02,  7.7195e-02, -5.6953e-02, -8.3469e-02,  3.9030e-02],\n",
      "        [ 5.1664e-02, -1.0105e-01,  4.9986e-02, -3.8720e-02, -6.8276e-02,\n",
      "         -6.3477e-02, -1.5282e-03,  4.5057e-02, -2.6699e-02, -8.9456e-02,\n",
      "          7.9145e-02, -4.0196e-02,  9.7477e-02, -7.8764e-02, -8.8921e-02,\n",
      "          3.7742e-02, -8.5437e-02, -1.5129e-02, -4.3982e-02, -7.0140e-02,\n",
      "          6.0139e-02,  4.7119e-02, -1.3331e-02,  8.7748e-02, -1.7565e-02,\n",
      "          2.3093e-02,  2.4557e-02, -5.7786e-02, -7.5115e-03,  2.2283e-02,\n",
      "         -4.3517e-02,  4.3316e-02,  3.4843e-02, -2.9851e-03,  9.5495e-02,\n",
      "          7.8819e-02, -6.8671e-02,  9.7275e-02, -1.0144e-01, -9.3134e-02,\n",
      "         -3.6505e-02, -8.5904e-03, -4.3696e-02, -1.0452e-01, -3.9531e-02,\n",
      "         -4.6952e-03,  1.0970e-01, -4.4622e-02,  1.8555e-02,  2.9753e-02,\n",
      "          9.0863e-03,  1.0312e-01,  1.2014e-03, -6.4856e-02,  4.6986e-02,\n",
      "          5.1431e-02, -9.5970e-02, -1.0664e-01, -1.0234e-01, -1.0519e-01,\n",
      "         -2.1267e-02, -2.2109e-02, -8.1276e-02, -8.9760e-02, -4.9971e-02,\n",
      "         -4.5703e-02,  8.4532e-02, -6.1212e-02, -2.0586e-02, -6.1594e-02,\n",
      "         -3.8069e-02,  1.3920e-02,  1.7536e-02, -8.2110e-02, -7.5226e-02,\n",
      "         -2.3079e-02, -7.6127e-02,  2.6847e-02,  6.4573e-02, -8.9483e-02],\n",
      "        [ 2.9392e-02,  8.9907e-02,  5.2959e-02,  2.7803e-02,  6.0749e-02,\n",
      "         -9.4037e-02, -2.4430e-02,  8.9147e-02,  1.0402e-01, -1.0546e-01,\n",
      "          1.0020e-01, -7.6809e-02,  1.1005e-01,  6.3083e-02, -9.3595e-02,\n",
      "          1.9863e-02, -1.0128e-01, -5.8711e-02, -4.4622e-02,  7.3795e-02,\n",
      "         -6.7261e-03,  1.0089e-01, -9.6222e-02, -9.5007e-02,  9.8065e-02,\n",
      "         -2.8258e-02,  6.4562e-02, -3.9684e-02,  6.6326e-02,  3.2951e-02,\n",
      "          1.1170e-01, -3.0681e-02,  2.0793e-02, -7.1842e-02,  5.6901e-02,\n",
      "         -1.6442e-02, -6.0524e-02, -8.0716e-02, -4.9542e-03, -8.2706e-02,\n",
      "          1.0257e-01, -6.6189e-02,  1.8156e-02, -9.9214e-02, -6.9031e-02,\n",
      "         -4.2872e-03,  7.6547e-02,  1.1105e-01,  7.7546e-02,  1.3526e-02,\n",
      "         -5.9887e-02,  6.1286e-02, -2.1055e-02, -8.0435e-02, -5.0104e-02,\n",
      "          3.3188e-02,  7.1771e-02, -5.2121e-04, -1.1109e-01, -2.8996e-02,\n",
      "          4.2880e-02, -9.8958e-02,  5.5872e-02, -7.6561e-02,  7.5509e-03,\n",
      "          8.9852e-02,  8.8836e-02,  9.1090e-02, -2.3408e-02,  3.9852e-02,\n",
      "          6.8538e-02, -9.0645e-02, -9.0980e-02, -3.5233e-02,  8.6951e-02,\n",
      "         -2.0389e-02,  5.8534e-02,  1.0149e-01,  9.5230e-02, -8.9170e-02],\n",
      "        [ 1.3638e-03,  1.8335e-02, -7.6636e-02,  6.9270e-02,  1.1305e-02,\n",
      "         -3.0565e-03, -5.4076e-02, -4.6492e-02, -8.1395e-02,  4.4098e-02,\n",
      "          7.8646e-02, -1.0993e-01,  9.4051e-02, -3.2993e-02, -9.5949e-02,\n",
      "          9.9750e-02,  3.2730e-02,  9.7392e-02, -5.9634e-03,  9.9582e-02,\n",
      "          6.6883e-02, -7.5289e-02,  4.3816e-02, -9.7534e-02, -8.1638e-02,\n",
      "          4.8152e-02, -1.8757e-02, -1.0220e-02,  5.9791e-02,  1.9716e-02,\n",
      "         -1.7923e-02,  3.8493e-02, -5.1033e-02,  2.8806e-02, -1.0553e-02,\n",
      "          9.0944e-02, -9.4195e-02,  2.6790e-02, -2.6480e-02, -7.5760e-02,\n",
      "          8.6347e-02, -1.0997e-01,  4.2400e-02, -6.0085e-02, -8.8901e-02,\n",
      "          1.0496e-01, -8.1562e-02, -2.8444e-03,  3.3725e-02, -6.9550e-02,\n",
      "          6.8394e-02, -7.4002e-02, -1.9790e-02,  1.0373e-01,  6.9481e-02,\n",
      "          3.8465e-02, -9.4049e-02,  4.7375e-02,  1.2889e-03, -5.5257e-02,\n",
      "         -8.2982e-02, -2.6298e-02, -7.5137e-03,  6.4710e-02, -7.9682e-02,\n",
      "         -1.1148e-01, -7.5737e-02, -8.2369e-02,  9.7794e-02,  6.8853e-02,\n",
      "         -9.2946e-02, -1.3100e-02, -9.5402e-02,  4.3721e-02,  1.0352e-01,\n",
      "         -3.5185e-03, -7.7268e-02, -7.5439e-02, -2.0155e-02, -9.9325e-02],\n",
      "        [ 7.8798e-02, -1.7404e-02,  5.7952e-03, -8.4280e-02,  4.1472e-02,\n",
      "          4.9895e-02, -6.1440e-02,  7.6795e-02, -9.5076e-02,  8.3350e-02,\n",
      "          2.6086e-02, -1.0776e-01, -6.7205e-03, -4.4760e-02,  1.6491e-03,\n",
      "         -6.7888e-02,  1.5474e-02,  5.9380e-02, -6.0870e-04,  1.0702e-01,\n",
      "          1.3831e-02, -9.0181e-02, -7.2927e-02, -2.4184e-02,  8.8032e-02,\n",
      "          8.8301e-02,  2.8253e-02, -5.8319e-02, -7.5877e-02,  8.3659e-02,\n",
      "          1.3099e-04,  8.5261e-02, -9.5216e-02, -6.0803e-03,  9.3192e-02,\n",
      "          3.5334e-02,  7.1311e-02,  8.1235e-02,  4.6320e-02,  1.0917e-01,\n",
      "         -4.0021e-02, -8.6322e-02,  9.8438e-02, -9.4192e-02,  8.1460e-02,\n",
      "          7.0050e-02, -9.6201e-02,  1.8211e-02, -3.4967e-03, -2.0681e-02,\n",
      "         -7.0499e-02, -2.8344e-02, -9.8446e-03, -3.3777e-02, -4.4719e-04,\n",
      "          5.5212e-03,  7.2690e-02,  5.5974e-02, -1.5521e-02, -5.1466e-02,\n",
      "          5.3663e-02,  3.3393e-02,  9.3984e-02, -7.7754e-02, -1.4875e-02,\n",
      "         -2.4444e-03, -7.2737e-02, -3.3115e-02,  9.3275e-02,  9.0357e-02,\n",
      "          3.0858e-02,  6.7414e-02, -1.5732e-03,  6.4723e-02, -9.5588e-02,\n",
      "         -6.4009e-02,  9.8646e-03,  4.8627e-02,  8.8705e-03,  4.0030e-02],\n",
      "        [ 4.3193e-02, -1.0922e-01, -1.1179e-01,  7.3086e-03, -4.0218e-02,\n",
      "         -2.8621e-02, -4.1929e-02, -2.2884e-03,  2.4182e-02, -4.4335e-03,\n",
      "          5.0318e-02,  8.8919e-02, -6.0120e-03, -5.1067e-03, -2.5566e-02,\n",
      "          4.5662e-02,  3.5293e-02, -7.3207e-02, -8.6165e-04, -9.4411e-02,\n",
      "         -3.2564e-02, -9.7079e-02, -5.2411e-02, -9.2806e-02, -5.5005e-02,\n",
      "         -1.0997e-01, -9.5417e-02, -5.6181e-02, -8.6743e-02,  1.4077e-02,\n",
      "         -9.0015e-02,  8.5958e-02,  6.0425e-02, -3.7541e-02, -8.2057e-02,\n",
      "         -1.9523e-02,  7.3173e-02, -8.1772e-02,  2.5124e-02, -6.1488e-02,\n",
      "         -3.7676e-02, -5.4574e-02, -1.1010e-01,  1.0334e-01, -9.0440e-02,\n",
      "          7.2640e-04,  7.9050e-02,  1.5810e-02, -8.0205e-02, -6.4022e-02,\n",
      "          2.1746e-02,  1.9888e-02,  8.5879e-03,  3.3461e-03, -7.0326e-02,\n",
      "         -3.2337e-02, -4.0624e-03, -1.0396e-01,  7.7471e-02,  3.7570e-02,\n",
      "         -7.3353e-03,  9.7766e-02,  8.7796e-02, -4.9326e-02, -7.7103e-02,\n",
      "          8.8313e-03, -8.0628e-02,  8.2499e-02,  9.5993e-02, -4.4526e-02,\n",
      "         -6.9887e-02, -1.0138e-01, -8.8276e-02, -6.0026e-02, -1.0431e-01,\n",
      "         -3.0398e-02, -3.3507e-02,  8.5875e-02, -4.1018e-02, -1.1000e-01],\n",
      "        [-7.1346e-02, -8.0927e-02, -3.5049e-03, -8.1125e-02, -7.7460e-02,\n",
      "          8.6123e-02, -1.5058e-02,  1.0971e-01,  1.0305e-01, -9.2101e-02,\n",
      "         -9.6102e-02, -1.1153e-01,  6.5825e-03,  7.9572e-02, -1.9690e-02,\n",
      "         -8.3766e-02, -7.4084e-03,  6.1345e-02,  8.6234e-02, -2.2668e-02,\n",
      "         -7.7061e-05, -2.0433e-02, -1.6311e-02,  3.8845e-02,  8.4788e-02,\n",
      "          5.8641e-02, -1.0853e-01, -3.2860e-02, -6.6324e-02,  5.5263e-02,\n",
      "          5.5045e-02, -5.7472e-02, -6.7779e-02, -1.0210e-01,  3.7329e-02,\n",
      "          6.4825e-02, -7.1251e-02,  9.0636e-02,  2.3502e-02, -2.4350e-02,\n",
      "         -1.8250e-02, -1.0456e-01,  8.3271e-03, -2.8346e-02,  2.1372e-02,\n",
      "          8.8199e-02, -9.4019e-02,  5.3297e-02, -1.0361e-01, -7.0886e-02,\n",
      "         -5.6935e-02,  4.3492e-02,  2.7716e-02, -2.5509e-02,  1.1118e-01,\n",
      "          3.3346e-02, -2.2806e-02,  8.3670e-02,  1.1170e-01, -1.0551e-01,\n",
      "         -4.2428e-03,  5.4943e-02, -5.6550e-02, -7.9218e-02, -8.3979e-02,\n",
      "          3.7909e-02,  9.0171e-02, -5.3083e-02,  1.0043e-01, -1.7344e-03,\n",
      "          3.5493e-02, -2.1455e-02,  5.6166e-02,  1.0971e-01,  5.7994e-03,\n",
      "         -7.4753e-03, -7.8095e-02,  1.0243e-01, -3.8945e-02,  1.0604e-01]],\n",
      "       requires_grad=True)\n",
      "name: fc3.bias, param: Parameter containing:\n",
      "tensor([-0.0950,  0.0185, -0.0637, -0.0976,  0.0878,  0.0483,  0.0056,  0.0865,\n",
      "        -0.0261,  0.0012], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for name, parameters in model.named_parameters():   # 各层参数及具体数字\n",
    "    print('name: {}, param: {}'.format(name, parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name:conv1, children:Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "name:conv2, children:Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "name:fc1, children:Linear(in_features=400, out_features=120, bias=True)\n",
      "name:fc2, children:Linear(in_features=120, out_features=80, bias=True)\n",
      "name:fc3, children:Linear(in_features=80, out_features=10, bias=True)\n"
     ]
    }
   ],
   "source": [
    "for n, c in model.named_children():    # 各层名称与具体定义\n",
    "    print(\"name:{}, children:{}\".format(n,c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 数据集的准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_trans = transforms.Compose([\n",
    "    transforms.Resize(32),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST('data', train=True, download=True, transform=data_trans)\n",
    "test_data = datasets.MNIST('data', train=False, download=True, transform=data_trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "n_split = 0.9\n",
    "batch_size = 64\n",
    "model_dir = 'models'\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "model_name = \"lenet_mnist.pt\"\n",
    "model = LeNet()\n",
    "\n",
    "obj = CNNModel(model=model, \n",
    "               train_data=train_data, \n",
    "               test_data=test_data, \n",
    "               model_dir=model_dir, \n",
    "               model_name=model_name,\n",
    "               best_valid_loss=best_valid_loss, \n",
    "               n_split=n_split, \n",
    "               batch_size=batch_size, \n",
    "               epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(obj.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataParallel(\n",
      "  (module): LeNet(\n",
      "    (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "    (fc2): Linear(in_features=120, out_features=80, bias=True)\n",
      "    (fc3): Linear(in_features=80, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(obj.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1 | Train Loss:0.2314406042141725 | Train Acc:0.930002221563981 | Val Loss:0.09761913215860407 | Val Acc:0.9704122340425532\n",
      "Cost time: 0.642307702700297 mins.\n"
     ]
    }
   ],
   "source": [
    "obj.train_fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 0.07367058542029113 | Test Acc: 0.9765127388535032 |\n"
     ]
    }
   ],
   "source": [
    "obj.get_acc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
