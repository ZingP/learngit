{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Pytorch中神经网络模块化接口nn的了解:\n",
    "\n",
    "torch.nn是专门为神经网络设计的模块化接口。nn构建于autograd之上，可以用来定义和运行神经网络。\n",
    "nn.Module是nn中十分重要的类,包含网络各层的定义及forward方法。\n",
    "定义自已的网络：\n",
    "    需要继承nn.Module类，并实现forward方法。\n",
    "    一般把网络中具有可学习参数的层放在构造函数__init__()中，\n",
    "    不具有可学习参数的层(如ReLU)可放在构造函数中，也可不放在构造函数中(而在forward中使用nn.functional来代替)\n",
    "    \n",
    "    只要在nn.Module的子类中定义了forward函数，backward函数就会被自动实现(利用Autograd)。\n",
    "    在forward函数中可以使用任何Variable支持的函数，毕竟在整个pytorch构建的图中，是Variable在流动。还可以使用\n",
    "    if,for,print,log等python语法.\n",
    "    \n",
    "    注：Pytorch基于nn.Module构建的模型中，只支持mini-batch的Variable输入方式，\n",
    "    比如，只有一张输入图片，也需要变成 N x C x H x W 的形式：\n",
    "    \n",
    "    input_image = torch.FloatTensor(1, 28, 28)\n",
    "    input_image = Variable(input_image)\n",
    "    input_image = input_image.unsqueeze(0)   # 1 x 1 x 28 x 28\n",
    "\"\"\"\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        # nn.Module的子类函数必须在构造函数中执行父类的构造函数\n",
    "        super(LeNet, self).__init__()\n",
    "        # nn.Conv2d返回的是一个Conv2d class的一个对象，该类中包含forward函数的实现\n",
    "        # 当调用self.conv1(input)的时候，就会调用该类的forward函数\n",
    "        # 第一层conv1卷积层，in_channel=1,output_channel=6,kernel_size=5*5,input_size=32*32,output_size=28*28\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        # 第二层conv2，output_channel=6, kernel 5*5, output_size=10*10,input_size=14*14\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 80)\n",
    "        self.fc3 = nn.Linear(80, 10) # 不用增加softmax层，在cross_entropy的Loss中自动增加了Softmax\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)   # F.max_pool2d的返回值是一个Variable\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(x.shape[0], -1)  #？\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 模型训练与评估类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timer(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start = time.time()\n",
    "        func(*args,**kwargs)\n",
    "        end = time.time()\n",
    "        cost = end - start\n",
    "        print(\"Cost time: {} mins.\".format(cost/60)) \n",
    "    return wrapper\n",
    "\n",
    "class CNNModel(object):\n",
    "    def __init__(self, model, train_data, test_data, model_dir, model_name,\n",
    "                 best_valid_loss=float('inf'), n_split=0.9, batch_size=64, epochs=10):\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.best_valid_loss = best_valid_loss\n",
    "        self.model_dir = model_dir\n",
    "        self.model_name = model_name\n",
    "        self.n_split = n_split\n",
    "        \n",
    "        self.train_data =  train_data\n",
    "        self.test_data = test_data\n",
    "        \n",
    "        self.device = self.get_device()\n",
    "        self.init_data()\n",
    "        self.init_iterator()\n",
    "        self.init_model_path()\n",
    "        \n",
    "        self.model = self.init_model(model)\n",
    "        self.optimizer = self.set_optimizer()\n",
    "        self.criterion = self.set_criterion()\n",
    "        \n",
    "    def get_device(self):\n",
    "        d = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        return d\n",
    "    \n",
    "    def init_data(self):\n",
    "        n_train = int(len(self.train_data)*self.n_split)\n",
    "        n_validation = len(self.train_data) - n_train\n",
    "        self.train_data, self.valid_data = torch.utils.data.random_split(self.train_data, [n_train, n_validation])\n",
    "    \n",
    "    def init_iterator(self):\n",
    "        self.train_iterator = torch.utils.data.DataLoader(self.train_data, shuffle=True, batch_size=self.batch_size)\n",
    "        self.valid_iterator = torch.utils.data.DataLoader(self.valid_data, batch_size=self.batch_size)\n",
    "        self.test_iterator = torch.utils.data.DataLoader(self.test_data, batch_size=self.batch_size)\n",
    "        \n",
    "    def set_optimizer(self):\n",
    "        optimizer = optim.Adam(self.model.parameters()) \n",
    "        return optimizer\n",
    "    \n",
    "    def set_criterion(self):\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        return criterion\n",
    "    \n",
    "    def init_model(self, model):\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            model = nn.DataParallel(model)\n",
    "        model = model.to(self.device)\n",
    "        return model\n",
    "        \n",
    "    def init_model_path(self):\n",
    "        if not os.path.isdir(self.model_dir):\n",
    "            os.makedirs(self.model_dir)\n",
    "        self.model_path = os.path.join(self.model_dir, self.model_name)\n",
    "        \n",
    "    # 定义评估函数\n",
    "    def accu(self, fx, y):\n",
    "        pred = fx.max(1,keepdim=True)[1]\n",
    "        correct = pred.eq(y.view_as(pred)).sum()  # 得到该batch的准确度\n",
    "        acc = correct.float()/pred.shape[0]\n",
    "        return acc\n",
    "\n",
    "    def train(self):\n",
    "        epoch_loss = 0   # 积累变量\n",
    "        epoch_acc = 0    # 积累变量\n",
    "        self.model.train()    # 该函数表示PHASE=Train\n",
    "\n",
    "        for (x,y) in self.train_iterator:  # 拿去每一个minibatch\n",
    "            x = x.to(self.device)\n",
    "            y = y.to(self.device)\n",
    "            self.optimizer.zero_grad()\n",
    "            fx = self.model(x)           # 进行forward\n",
    "            loss = self.criterion(fx,y)  # 计算Loss,train_loss\n",
    "            type(loss)\n",
    "            acc = self.accu(fx,y)    # 计算精确度，train_accu\n",
    "            loss.backward()          # 进行BP\n",
    "            self.optimizer.step()    # 统一更新模型\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "\n",
    "        return epoch_loss/len(self.train_iterator),epoch_acc/len(self.train_iterator)\n",
    "\n",
    "    def evaluate(self, iterator):\n",
    "        epoch_loss = 0\n",
    "        epoch_acc = 0\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for (x,y) in iterator:\n",
    "                x = x.to(self.device)\n",
    "                y = y.to(self.device)\n",
    "                fx = self.model(x)\n",
    "                loss = self.criterion(fx,y)\n",
    "                acc = self.accu(fx,y)\n",
    "                epoch_loss += loss.item()\n",
    "                epoch_acc += acc.item()\n",
    "        return epoch_loss/len(iterator),epoch_acc/len(iterator)\n",
    "    \n",
    "    @timer\n",
    "    def train_fit(self):\n",
    "        info = 'Epoch:{0} | Train Loss:{1} | Train Acc:{2} | Val Loss:{3} | Val Acc:{4}'\n",
    "        for epoch in range(self.epochs):\n",
    "            train_loss, train_acc = self.train()\n",
    "            valid_loss, valid_acc = self.evaluate(self.valid_iterator)\n",
    "            if valid_loss < self.best_valid_loss:  # 如果是最好的模型就保存到文件夹\n",
    "                self.best_valid_loss = valid_loss\n",
    "                torch.save(self.model.state_dict(), self.model_path)\n",
    "            print(info.format(epoch+1, train_loss, train_acc, valid_loss, valid_acc))\n",
    "    \n",
    "    def get_acc(self):\n",
    "        self.model.load_state_dict(torch.load(self.model_path))\n",
    "        test_loss, test_acc = self.evaluate(self.test_iterator)\n",
    "        print('| Test Loss: {0} | Test Acc: {1} |'.format(test_loss,test_acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 数据集的准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_trans = transforms.Compose([\n",
    "    transforms.Resize(32),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST('data', train=True, download=True, transform=data_trans)\n",
    "test_data = datasets.MNIST('data', train=False, download=True, transform=data_trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "n_split = 0.9\n",
    "batch_size = 64\n",
    "model_dir = 'models'\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "model_name = \"lenet_mnist.pt\"\n",
    "model = LeNet()\n",
    "\n",
    "obj = CNNModel(model=model, \n",
    "               train_data=train_data, \n",
    "               test_data=test_data, \n",
    "               model_dir=model_dir, \n",
    "               model_name=model_name,\n",
    "               best_valid_loss=best_valid_loss, \n",
    "               n_split=n_split, \n",
    "               batch_size=batch_size, \n",
    "               epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(obj.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataParallel(\n",
      "  (module): LeNet(\n",
      "    (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "    (fc2): Linear(in_features=120, out_features=80, bias=True)\n",
      "    (fc3): Linear(in_features=80, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(obj.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1 | Train Loss:0.23474845162623725 | Train Acc:0.9299590245101124 | Val Loss:0.0772893229856136 | Val Acc:0.9765070924099456\n",
      "Cost time: 0.6375023643175761 mins.\n"
     ]
    }
   ],
   "source": [
    "obj.train_fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 0.06879637322750441 | Test Acc: 0.9774084394904459 |\n"
     ]
    }
   ],
   "source": [
    "obj.get_acc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
