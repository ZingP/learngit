{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride):\n",
    "        super(ResNetBlock,self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.downsample = nn.Sequential()\n",
    "        \n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.downsample(x)#ResNet的add操作，其实是张量的加和\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNetLayer(nn.Module):\n",
    "    def __init__(self,block,n_blocks,in_channels,out_channels,stride):\n",
    "        super(ResNetLayer,self).__init__()\n",
    "        self.modules=[]\n",
    "        self.modules.append(block(in_channels,out_channels,stride))\n",
    "        for _ in range(n_blocks-1):\n",
    "            self.modules.append(block(out_channels,out_channels,1))\n",
    "        self.blocks=nn.Sequential(*self.modules)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return self.blocks(x)\n",
    "    \n",
    "class ResNet18(nn.Module):\n",
    "    def __init__(self,layer,block):\n",
    "        super(ResNet18,self).__init__()\n",
    "        n_blocks=[2,2,2,2]\n",
    "        self.conv1=nn.Conv2d(1,64,kernel_size=3,stride=1,padding=1,bias=False)\n",
    "        self.bn1=nn.BatchNorm2d(64)\n",
    "        self.rb1=layer(block,n_blocks[0],64,64,1)\n",
    "        self.rb2=layer(block,n_blocks[1],64,128,2)\n",
    "        self.rb3=layer(block,n_blocks[2],128,256,2)\n",
    "        self.rb4=layer(block,n_blocks[3],256,512,2)\n",
    "        self.fc=nn.Linear(512,10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out=F.relu(self.bn1(self.conv1(x)))\n",
    "        out=self.rb1(out)\n",
    "        out=self.rb2(out)\n",
    "        out=self.rb3(out)\n",
    "        out=self.rb4(out)\n",
    "        out=F.avg_pool2d(out,4)\n",
    "        out=out.view(out.shape[0],-1)\n",
    "        out=self.fc(out)\n",
    "        return out\n",
    "        \n",
    "#ResNet34->[3,4,6,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 模型训练与评估类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timer(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start = time.time()\n",
    "        func(*args,**kwargs)\n",
    "        end = time.time()\n",
    "        cost = end - start\n",
    "        print(\"Cost time: {} mins.\".format(cost/60)) \n",
    "    return wrapper\n",
    "\n",
    "\n",
    "class CNNModel(object):\n",
    "    def __init__(self, model, train_data, test_data, model_dir, model_name,\n",
    "                 best_valid_loss=float('inf'), n_split=0.9, batch_size=64, epochs=10):\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.best_valid_loss = best_valid_loss\n",
    "        self.model_dir = model_dir\n",
    "        self.model_name = model_name\n",
    "        self.n_split = n_split\n",
    "        \n",
    "        self.train_data =  train_data\n",
    "        self.test_data = test_data\n",
    "        \n",
    "        self.device = self.get_device()\n",
    "        self.init_data()\n",
    "        self.init_iterator()\n",
    "        self.init_model_path()\n",
    "        \n",
    "        self.model = self.init_model(model)\n",
    "        self.optimizer = self.set_optimizer()\n",
    "        self.criterion = self.set_criterion()\n",
    "        \n",
    "    def get_device(self):\n",
    "        d = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        return d\n",
    "    \n",
    "    def init_data(self):\n",
    "        n_train = int(len(self.train_data)*self.n_split)\n",
    "        n_validation = len(self.train_data) - n_train\n",
    "        self.train_data, self.valid_data = torch.utils.data.random_split(self.train_data, [n_train, n_validation])\n",
    "    \n",
    "    def init_iterator(self):\n",
    "        self.train_iterator = torch.utils.data.DataLoader(self.train_data, shuffle=True, batch_size=self.batch_size)\n",
    "        self.valid_iterator = torch.utils.data.DataLoader(self.valid_data, batch_size=self.batch_size)\n",
    "        self.test_iterator = torch.utils.data.DataLoader(self.test_data, batch_size=self.batch_size)\n",
    "        \n",
    "    def set_optimizer(self):\n",
    "        optimizer = optim.Adam(self.model.parameters()) \n",
    "        return optimizer\n",
    "    \n",
    "    def set_criterion(self):\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        return criterion\n",
    "    \n",
    "    def init_model(self, model):\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            model = nn.DataParallel(model)\n",
    "        model = model.to(self.device)\n",
    "        return model\n",
    "        \n",
    "    def init_model_path(self):\n",
    "        if not os.path.isdir(self.model_dir):\n",
    "            os.makedirs(self.model_dir)\n",
    "        self.model_path = os.path.join(self.model_dir, self.model_name)\n",
    "        \n",
    "    # 定义评估函数\n",
    "    def accu(self, fx, y):\n",
    "        pred = fx.max(1,keepdim=True)[1]\n",
    "        correct = pred.eq(y.view_as(pred)).sum()  # 得到该batch的准确度\n",
    "        acc = correct.float()/pred.shape[0]\n",
    "        return acc\n",
    "\n",
    "    def train(self):\n",
    "        epoch_loss = 0   # 积累变量\n",
    "        epoch_acc = 0    # 积累变量\n",
    "        self.model.train()    # 该函数表示PHASE=Train\n",
    "\n",
    "        for (x,y) in self.train_iterator:  # 拿去每一个minibatch\n",
    "            x = x.to(self.device)\n",
    "            y = y.to(self.device)\n",
    "            self.optimizer.zero_grad()\n",
    "            fx = self.model(x)           # 进行forward\n",
    "            loss = self.criterion(fx,y)  # 计算Loss,train_loss\n",
    "            type(loss)\n",
    "            acc = self.accu(fx,y)      # 计算精确度，train_accu\n",
    "            loss.backward()     # 进行BP\n",
    "            self.optimizer.step()    # 统一更新模型\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "\n",
    "        return epoch_loss/len(self.train_iterator),epoch_acc/len(self.train_iterator)\n",
    "\n",
    "    def evaluate(self, iterator):\n",
    "        epoch_loss = 0\n",
    "        epoch_acc = 0\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for (x,y) in iterator:\n",
    "                x = x.to(self.device)\n",
    "                y = y.to(self.device)\n",
    "                fx = self.model(x)\n",
    "                loss = self.criterion(fx,y)\n",
    "                acc = self.accu(fx,y)\n",
    "                epoch_loss += loss.item()\n",
    "                epoch_acc += acc.item()\n",
    "        return epoch_loss/len(iterator),epoch_acc/len(iterator)\n",
    "    \n",
    "    @timer\n",
    "    def train_fit(self):\n",
    "        info = 'Epoch:{0} | Train Loss:{1} | Train Acc:{2} | Val Loss:{3} | Val Acc:{4}'\n",
    "        for epoch in range(self.epochs):\n",
    "            train_loss, train_acc = self.train()\n",
    "            valid_loss, valid_acc = self.evaluate(self.valid_iterator)\n",
    "            if valid_loss < self.best_valid_loss:  # 如果是最好的模型就保存到文件夹\n",
    "                self.best_valid_loss = valid_loss\n",
    "                torch.save(self.model.state_dict(), self.model_path)\n",
    "            print(info.format(epoch+1, train_loss, train_acc, valid_loss, valid_acc))\n",
    "    \n",
    "    def get_acc(self):\n",
    "        self.model.load_state_dict(torch.load(self.model_path))\n",
    "        test_loss, test_acc = self.evaluate(self.test_iterator)\n",
    "        print('| Test Loss: {0} | Test Acc: {1} |'.format(test_loss,test_acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 数据集的准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_trans = transforms.Compose([\n",
    "    transforms.Resize(32),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST('data', train=True, download=True, transform=data_trans)\n",
    "test_data = datasets.MNIST('data', train=False, download=True, transform=data_trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "n_split = 0.9\n",
    "batch_size = 64\n",
    "model_dir = 'models'\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "model_name = \"resnet18_mnist.pt\"\n",
    "model = ResNet18(ResNetLayer,ResNetBlock)\n",
    "\n",
    "resnet18 = CNNModel(model=model, \n",
    "               train_data=train_data, \n",
    "               test_data=test_data, \n",
    "               model_dir=model_dir, \n",
    "               model_name=model_name,\n",
    "               best_valid_loss=best_valid_loss, \n",
    "               n_split=n_split, \n",
    "               batch_size=batch_size, \n",
    "               epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(resnet18.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataParallel(\n",
      "  (module): ResNet18(\n",
      "    (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (rb1): ResNetLayer(\n",
      "      (blocks): Sequential(\n",
      "        (0): ResNetBlock(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (downsample): Sequential()\n",
      "        )\n",
      "        (1): ResNetBlock(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (downsample): Sequential()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (rb2): ResNetLayer(\n",
      "      (blocks): Sequential(\n",
      "        (0): ResNetBlock(\n",
      "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): ResNetBlock(\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (downsample): Sequential()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (rb3): ResNetLayer(\n",
      "      (blocks): Sequential(\n",
      "        (0): ResNetBlock(\n",
      "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): ResNetBlock(\n",
      "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (downsample): Sequential()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (rb4): ResNetLayer(\n",
      "      (blocks): Sequential(\n",
      "        (0): ResNetBlock(\n",
      "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): ResNetBlock(\n",
      "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (downsample): Sequential()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(resnet18.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1 | Train Loss:0.12044534862253338 | Train Acc:0.9642143068720379 | Val Loss:0.04958334660276453 | Val Acc:0.984375\n",
      "Cost time: 4.138012305895487 mins.\n"
     ]
    }
   ],
   "source": [
    "resnet18.train_fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 0.040915817176555375 | Test Acc: 0.9883558917197452 |\n"
     ]
    }
   ],
   "source": [
    "resnet18.get_acc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
