{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-57a943b824d1>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /root/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /root/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /root/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /root/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ./MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /root/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "# 如果MNIST_data不存在会先下载再读入，pytorch的数据集和这个不一样。\n",
    "mnist=input_data.read_data_sets('./MNIST_data',one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 28*28*1 灰度图被拉成一行了\n",
    "mnist.train.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 784)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 验证集\n",
    "mnist.validation.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 循环读，共55000张\n",
    "train_x,train_y=mnist.train.next_batch(20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 784)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试集\n",
    "test_x, test_y = mnist.test.next_batch(5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 图像的可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rc('image',cmap='binary')\n",
    "for i in range(10):#打印10张图\n",
    "    plt.subplot(2,5,i+1)\n",
    "    # 打印图用imshow\n",
    "    plt.imshow(train_x[i].reshape(28,28))\n",
    "    print(train_y[i])\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "plt.tight_layout()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 全连接神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Sequential 相当于pipeline，会自动执行forward和bp\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model1():\n",
    "    model=Sequential()\n",
    "    model.add(Dense(784,activation='relu'))\n",
    "    model.add(Dense(100,activation='relu'))\n",
    "    model.add(Dense(100,activation='relu'))\n",
    "    model.add(Dense(10,activation='softmax'))\n",
    "    model.compile(optimizer='adam',loss='categorical_crossentropy')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = model1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 11s 541us/step - loss: 0.3057\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 11s 559us/step - loss: 0.1275\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 10s 497us/step - loss: 0.0873\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 10s 477us/step - loss: 0.0628\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 9s 473us/step - loss: 0.0513\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 9s 473us/step - loss: 0.0378\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 9s 471us/step - loss: 0.0317\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 10s 475us/step - loss: 0.0274\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 10s 480us/step - loss: 0.0261\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 9s 473us/step - loss: 0.0238\n"
     ]
    }
   ],
   "source": [
    "history = m.fit(train_x,train_y,epochs=10,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = m.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9676"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(pred.argmax(1),test_y.argmax(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 卷积神经网络RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir='models'\n",
    "if not os.path.isdir(model_dir):\n",
    "    os.makedirs(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不像TensorFlow一样有GPU和CPU版本，安装的时候pytorch会自动识别CPU还是GPU\n",
    "import torch\n",
    "# nn就是各种层\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# optim是优化器\n",
    "import torch.optim as optim\n",
    "# torchvision有optim的一些东西\n",
    "import torchvision\n",
    "# trainsforms相当于pipeline\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import random\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定一个transforms\n",
    "# compose相当于一个pipeline，链式调用\n",
    "data_trans = transforms.Compose([\n",
    "    transforms.Resize(32),   # resize是防止在多层网络中图像提前变成1*1\n",
    "    transforms.ToTensor()\n",
    "#    transforms.Normalize(()())?<-参数mean和std来自于训练集，但是transform本身会在训练和评测的时候都会使用\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 图像的Normalize\n",
    "\n",
    "- 目的：将图片进行归一化的缩放|(x-mean)/std\n",
    "    - 如果不归一化，可能导致梯度爆炸或者梯度衰减、梯度为零。矩阵是相乘的，网络越深，连乘越多。如果梯度都大于1就会越乘越大，导致梯度爆炸，上溢出；如果梯度小于1，会越来越小，最终导致梯度为0。\n",
    "\n",
    "- 思考：图片归一化后，真的不存在小于0或者大于1的outlier了吗？ \n",
    "    - 不一定，如果数据不均匀，可能导致小于0或者大于1的数据。\n",
    "\n",
    "- 思考：归一化哪部分数据？A 训练集 B 评测集 C 训练集+评测集？ A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13251463"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(mnist.test.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31048033"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(mnist.test.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_trans=transforms.Compose([\n",
    "    transforms.Resize(32),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,),(0.3081,))#参数mean和std来自于训练集，但是transform本身会在训练和评测的时候都会使用\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=datasets.MNIST('data',train=True,download=True,transform=data_trans)\n",
    "test_data=datasets.MNIST('data',train=False,download=True,transform=data_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train=int(len(train_data)*0.9)\n",
    "n_validation=len(train_data)-n_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,valid_data=torch.utils.data.random_split(train_data,[n_train,n_validation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54000 6000 10000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data),len(valid_data),len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 目前完成了数据集的制作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator=torch.utils.data.DataLoader(train_data,shuffle=True,batch_size=batch_size)\n",
    "valid_iterator=torch.utils.data.DataLoader(valid_data,batch_size=batch_size)\n",
    "test_iterator=torch.utils.data.DataLoader(test_data,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet,self).__init__()\n",
    "        #第一层conv1卷积层，in_channel=1,output_channel=6,kernel_size=5*5,input_size=32*32,output_size=28*28\n",
    "        self.conv1=nn.Conv2d(1,6,5)\n",
    "        #第二层conv2，output_channel=6 ,kernel 5*5,output_size=10*10,input_size=14*14\n",
    "        self.conv2=nn.Conv2d(6,16,5)\n",
    "        \n",
    "        self.fc1=nn.Linear(16*5*5,120)\n",
    "        \n",
    "        self.fc2=nn.Linear(120,80)\n",
    "        \n",
    "        self.fc3=nn.Linear(80,10)#不用增加softmax层，在cross_entropy的Loss中自动增加了Softmax\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=F.max_pool2d(F.relu(self.conv1(x)),2)\n",
    "        x=F.max_pool2d(F.relu(self.conv2(x)),2)\n",
    "        x=x.view(x.shape[0],-1)\n",
    "        x=F.relu(self.fc1(x))\n",
    "        x=F.relu(self.fc2(x))\n",
    "        x=self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 到此神经网络定义完毕\n",
    "\n",
    "## 载入模型并训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=LeNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeNet(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=80, bias=True)\n",
       "  (fc3): Linear(in_features=80, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 如何评价\n",
    "- 计算精确度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accu(fx,y):\n",
    "    pred=fx.max(1,keepdim=True)[1]\n",
    "    correct=pred.eq(y.view_as(pred)).sum()#得到该batch的准确度\n",
    "    acc=correct.float()/pred.shape[0]\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,device,iterator,optimizer,criterion):\n",
    "    epoch_loss=0#积累变量\n",
    "    epoch_acc=0#积累变量\n",
    "    model.train()#该函数表示PHASE=Train\n",
    "    \n",
    "    for (x,y) in iterator:#拿去每一个minibatch\n",
    "        x=x.to(device)\n",
    "        y=y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        fx=model(x)#进行forward\n",
    "        loss=criterion(fx,y)#计算Loss,train_loss\n",
    "        type(loss)\n",
    "        acc=accu(fx,y)#计算精确度，train_accu\n",
    "        loss.backward()#进行BP\n",
    "        optimizer.step()#统一更新模型\n",
    "        epoch_loss+=loss.item()\n",
    "        epoch_acc+=acc.item()\n",
    "        \n",
    "    return epoch_loss/len(iterator),epoch_acc/len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model,device,iterator,criterion):\n",
    "    epoch_loss=0\n",
    "    epoch_acc=0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for (x,y) in iterator:\n",
    "            x=x.to(device)\n",
    "            y=y.to(device)\n",
    "            fx=model(x)\n",
    "            loss=criterion(fx,y)\n",
    "            acc=accu(fx,y)\n",
    "            epoch_loss+=loss.item()\n",
    "            epoch_acc+=acc.item()\n",
    "    return epoch_loss/len(iterator),epoch_acc/len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=10\n",
    "model_path=os.path.join(model_dir,'lenet_mnist.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_valid_loss=float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1|Train Loss:0.24760320014651352|Train Acc:0.9246642970219607|Val Loss:0.10908676905834928|Val Acc:0.9671431735475012\n",
      "Epoch:2|Train Loss:0.07427523002222675|Train Acc:0.976815511476937|Val Loss:0.08388522075132486|Val Acc:0.9747340425531915\n",
      "Epoch:3|Train Loss:0.053126079695723|Train Acc:0.9832642180094787|Val Loss:0.06838884665333528|Val Acc:0.981216755319149\n",
      "Epoch:4|Train Loss:0.040222542934225634|Train Acc:0.9871149289099526|Val Loss:0.05522994688177045|Val Acc:0.983876329787234\n",
      "Epoch:5|Train Loss:0.03392185422402069|Train Acc:0.9893241508453379|Val Loss:0.053868640603081504|Val Acc:0.9833776595744681\n",
      "Epoch:6|Train Loss:0.028590797192871713|Train Acc:0.9906632602921029|Val Loss:0.047937486177072566|Val Acc:0.9876994680851063\n",
      "Epoch:7|Train Loss:0.023947799947969087|Train Acc:0.9924281694312796|Val Loss:0.045031971159450554|Val Acc:0.9870345744680851\n",
      "Epoch:8|Train Loss:0.020562630354192868|Train Acc:0.9932427428909952|Val Loss:0.04872167399066421|Val Acc:0.987533244680851\n",
      "Epoch:9|Train Loss:0.019539102830292913|Train Acc:0.9938475019982641|Val Loss:0.045055738689893106|Val Acc:0.988031914893617\n",
      "Epoch:10|Train Loss:0.017206260823022346|Train Acc:0.9944090639810427|Val Loss:0.04577537029585306|Val Acc:0.988031914893617\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    train_loss,train_acc=train(model,device,train_iterator,optimizer,criterion)\n",
    "    valid_loss,valid_acc=evaluate(model,device,valid_iterator,criterion)\n",
    "    if valid_loss<best_valid_loss:#如果是最好的模型就保存到文件夹\n",
    "        best_valid_loss=valid_loss\n",
    "        torch.save(model.state_dict(),model_path)\n",
    "    print('Epoch:{0}|Train Loss:{1}|Train Acc:{2}|Val Loss:{3}|Val Acc:{4}'.format(epoch+1,train_loss,train_acc,valid_loss,valid_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 0.0347950556760381 | Test Acc: 0.9887539808917197 |\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "test_loss, test_acc = evaluate(model, device, test_iterator, criterion)\n",
    "\n",
    "print('| Test Loss: {0} | Test Acc: {1} |'.format(test_loss,test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_num_threads(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_trans_alexnet = transforms.Compose([\n",
    "    transforms.Resize(227),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,),(0.3081,))#参数mean和std来自于训练集，但是transform本身会在训练和评测的时候都会使用\n",
    "])\n",
    "train_data = datasets.MNIST('data',train=True,download=True,transform=data_trans_alexnet)\n",
    "test_data = datasets.MNIST('data',train=False,download=True,transform=data_trans_alexnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train=int(len(train_data)*0.9)\n",
    "n_validation=len(train_data)-n_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,valid_data=torch.utils.data.random_split(train_data,[n_train,n_validation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54000 6000 10000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data),len(valid_data),len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator=torch.utils.data.DataLoader(train_data,shuffle=True,batch_size=batch_size)\n",
    "valid_iterator=torch.utils.data.DataLoader(valid_data,batch_size=batch_size)\n",
    "test_iterator=torch.utils.data.DataLoader(test_data,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self):#init函数定义的是网络的架构、关键的网络模块、模组\n",
    "        super(AlexNet,self).__init__()\n",
    "        self.feature_block=nn.Sequential(\n",
    "            nn.Conv2d(1,64,kernel_size=11,stride=4,padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3,stride=2),\n",
    "            nn.Conv2d(64,192,kernel_size=5,padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3,stride=2),\n",
    "            nn.Conv2d(192,384,kernel_size=3,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384,256,kernel_size=3,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256,256,kernel_size=3,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3,stride=2)\n",
    "        )\n",
    "        self.avgpool=nn.AdaptiveAvgPool2d((6,6))\n",
    "        self.class_block=nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256*6*6,4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096,4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096,10),\n",
    "        )\n",
    "    def forward(self,x):#数据的正向流\n",
    "        x = self.feature_block(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0),256*6*6)\n",
    "        x = self.class_block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AlexNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (feature_block): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (class_block): Sequential(\n",
       "    (0): Dropout(p=0.5)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace)\n",
       "    (3): Dropout(p=0.5)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace)\n",
       "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=10\n",
    "model_dir='models'\n",
    "model_path=os.path.join(model_dir,'alexnet_mnist.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_valid_loss=float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(model_dir):\n",
    "    os.makedirs(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1|Train Loss:0.2783555006277328|Train Acc:0.9086752073459715|Val Loss:0.07011570103783557|Val Acc:0.9805518617021277\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-128-ba5819ce1510>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_acc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_iterator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalid_loss\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mbest_valid_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m#如果是最好的模型就保存到文件夹\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mbest_valid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-42-82d08a2de87a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, iterator, optimizer, criterion)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0macc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#计算精确度，train_accu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#进行BP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#统一更新模型\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mepoch_loss\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mepoch_acc\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    train_loss,train_acc=train(model,device,train_iterator,optimizer,criterion)\n",
    "    valid_loss,valid_acc=evaluate(model,device,valid_iterator,criterion)\n",
    "    if valid_loss<best_valid_loss:#如果是最好的模型就保存到文件夹\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(),model_path)\n",
    "    print('Epoch:{0}|Train Loss:{1}|Train Acc:{2}|Val Loss:{3}|Val Acc:{4}'.format(epoch+1,train_loss,train_acc,valid_loss,valid_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-129-43b67fbdf3b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'| Test Loss: {0} | Test Acc: {1} |'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-43-c7e29a7c3e79>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, device, iterator, criterion)\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mfx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0macc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-119-6b850bea8295>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavgpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1350\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1352\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unwrap_optional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1353\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(model_path))\n",
    "test_loss, test_acc = evaluate(model, device, test_iterator, criterion)\n",
    "print('| Test Loss: {0} | Test Acc: {1} |'.format(test_loss,test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchvision.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.get_num_threads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
