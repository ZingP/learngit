{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mnist手写数字识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-c651a1ed2de4>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /root/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /root/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /root/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /root/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ./MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /root/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "# 如果MNIST_data不存在会先下载再读入，pytorch的数据集和这个不一样。\n",
    "mnist = input_data.read_data_sets('./MNIST_data',one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 28*28*1 灰度图被拉成一行了\n",
    "mnist.train.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 784)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 验证集\n",
    "mnist.validation.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 循环读，共55000张\n",
    "train_x,train_y = mnist.train.next_batch(20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 784)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试集\n",
    "test_x, test_y = mnist.test.next_batch(5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 图像的可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rc('image',cmap='binary')\n",
    "for i in range(10):#打印10张图\n",
    "    plt.subplot(2,5,i+1)\n",
    "    # 打印图用imshow\n",
    "    plt.imshow(train_x[i].reshape(28,28))\n",
    "    print(train_y[i])\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "plt.tight_layout()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 全连接神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Sequential 相当于pipeline，会自动执行forward和bp\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model1():\n",
    "    model=Sequential()\n",
    "    model.add(Dense(784,activation='relu'))\n",
    "    model.add(Dense(100,activation='relu'))\n",
    "    model.add(Dense(100,activation='relu'))\n",
    "    model.add(Dense(10,activation='softmax'))\n",
    "    model.compile(optimizer='adam',loss='categorical_crossentropy')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = model1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 9s 471us/step - loss: 0.3188\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 6s 297us/step - loss: 0.1266\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 6s 303us/step - loss: 0.0809\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 6s 300us/step - loss: 0.0605\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 6s 303us/step - loss: 0.0397\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 6s 301us/step - loss: 0.0394\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 6s 301us/step - loss: 0.0313\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 6s 300us/step - loss: 0.0279\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 6s 299us/step - loss: 0.0245\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 6s 300us/step - loss: 0.0236\n"
     ]
    }
   ],
   "source": [
    "history = m.fit(train_x,train_y,epochs=10,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = m.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9548"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(pred.argmax(1),test_y.argmax(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 卷积神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import time\n",
    "import random\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir='models'\n",
    "if not os.path.isdir(model_dir):\n",
    "    os.makedirs(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不像TensorFlow一样有GPU和CPU版本，安装的时候pytorch会自动识别CPU还是GPU\n",
    "import torch\n",
    "# nn就是各种层\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# optim是优化器\n",
    "import torch.optim as optim\n",
    "# torchvision有optim的一些东西\n",
    "import torchvision\n",
    "# trainsforms相当于pipeline\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 定一个transforms\n",
    "# # compose相当于一个pipeline，链式调用\n",
    "# data_trans = transforms.Compose([\n",
    "#     transforms.Resize(32),   # resize是防止在多层网络中图像提前变成1*1\n",
    "#     transforms.ToTensor()\n",
    "# #    transforms.Normalize(()())?<-参数mean和std来自于训练集，但是transform本身会在训练和评测的时候都会使用\n",
    "# ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 图像的Normalize\n",
    "\n",
    "- 目的：将图片进行归一化的缩放|(x-mean)/std\n",
    "    - 如果不归一化，可能导致梯度爆炸或者梯度衰减、梯度为零。矩阵是相乘的，网络越深，连乘越多。如果梯度都大于1就会越乘越大，导致梯度爆炸，上溢出；如果梯度小于1，会越来越小，最终导致梯度为0，梯度离散，相当于平滩底部，学不到什么东西。\n",
    "\n",
    "- 思考：图片归一化后，真的不存在小于0或者大于1的outlier了吗？\n",
    "    - 不一定，如果数据不均匀，可能导致小于0或者大于1的数据。归一化的公式？\n",
    "\n",
    "- 思考：归一化哪部分数据？\n",
    "    - A 训练集 B 评测集 C 训练集+评测集？     A\n",
    "    - 不可能得到全部数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13070044"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(mnist.train.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30815923"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(mnist.train.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_trans = transforms.Compose([\n",
    "    transforms.Resize(32),   # 防止提前出现1*1像素的图像\n",
    "    transforms.ToTensor(),   # 数据结构转换成torch能接收的\n",
    "    transforms.Normalize((0.1307,),(0.3081,))  # 参数mean和std来自于训练集，但是transform本身会在训练和评测的时候都会使用\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 会建立一个data目录，train是否是训练集。\n",
    "train_data = datasets.MNIST('data', train=True, download=True, transform=data_trans)\n",
    "test_data = datasets.MNIST('data', train=False, download=True, transform=data_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = int(len(train_data)*0.9)\n",
    "n_validation = len(train_data)-n_train    # 10%做评测集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,valid_data = torch.utils.data.random_split(train_data,[n_train,n_validation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54000 6000 10000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data),len(valid_data),len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 目前完成了数据集的制作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterator 相当于pytorch里面的一个object，对数据进行切分之后的数据结构。只有训练集有必要shuffle。\n",
    "train_iterator=torch.utils.data.DataLoader(train_data,shuffle=True,batch_size=batch_size)\n",
    "valid_iterator=torch.utils.data.DataLoader(valid_data,batch_size=batch_size)\n",
    "test_iterator=torch.utils.data.DataLoader(test_data,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet,self).__init__()\n",
    "        #第一层conv1卷积层，in_channel=1,output_channel=6,kernel_size=5*5,input_size=32*32,output_size=28*28\n",
    "        self.conv1=nn.Conv2d(1,6,5)\n",
    "        #第二层conv2，output_channel=6 ,kernel 5*5,output_size=10*10,input_size=14*14\n",
    "        self.conv2=nn.Conv2d(6,16,5)\n",
    "        self.fc1=nn.Linear(16*5*5,120)\n",
    "        self.fc2=nn.Linear(120,80)\n",
    "        self.fc3=nn.Linear(80,10)#不用增加softmax层，在cross_entropy的Loss中自动增加了Softmax\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=F.max_pool2d(F.relu(self.conv1(x)),2)\n",
    "        x=F.max_pool2d(F.relu(self.conv2(x)),2)\n",
    "        x=x.view(x.shape[0],-1)  #？\n",
    "        x=F.relu(self.fc1(x))\n",
    "        x=F.relu(self.fc2(x))\n",
    "        x=self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 到此神经网络定义完毕\n",
    "\n",
    "## 载入模型并训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=LeNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeNet(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=80, bias=True)\n",
       "  (fc3): Linear(in_features=80, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-01e6a7db4b03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# 优化器\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "optimizer=optim.Adam(model.parameters())   # 优化器\n",
    "criterion=nn.CrossEntropyLoss()    # loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=nn.CrossEntropyLoss()    # loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 如何评价\n",
    "- 计算精确度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accu(fx,y):\n",
    "    pred=fx.max(1,keepdim=True)[1]\n",
    "    correct=pred.eq(y.view_as(pred)).sum()#得到该batch的准确度\n",
    "    acc=correct.float()/pred.shape[0]\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,device,iterator,optimizer,criterion):\n",
    "    epoch_loss=0  #积累变量\n",
    "    epoch_acc=0   #积累变量\n",
    "    model.train() #该函数表示PHASE=Train\n",
    "    \n",
    "    for (x,y) in iterator:#拿去每一个minibatch\n",
    "        x=x.to(device)\n",
    "        y=y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        fx=model(x)#进行forward\n",
    "        loss=criterion(fx,y)#计算Loss,train_loss\n",
    "        type(loss)\n",
    "        acc=accu(fx,y)#计算精确度，train_accu\n",
    "        loss.backward()#进行BP\n",
    "        optimizer.step()#统一更新模型\n",
    "        epoch_loss+=loss.item()\n",
    "        epoch_acc+=acc.item()\n",
    "        \n",
    "    return epoch_loss/len(iterator),epoch_acc/len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model,device,iterator,criterion):\n",
    "    epoch_loss=0\n",
    "    epoch_acc=0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for (x,y) in iterator:\n",
    "            x=x.to(device)\n",
    "            y=y.to(device)\n",
    "            fx=model(x)\n",
    "            loss=criterion(fx,y)\n",
    "            acc=accu(fx,y)\n",
    "            epoch_loss+=loss.item()\n",
    "            epoch_acc+=acc.item()\n",
    "    return epoch_loss/len(iterator),epoch_acc/len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=10\n",
    "model_path=os.path.join(model_dir,'lenet_mnist.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_valid_loss=float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1|Train Loss:0.23972646112584672|Train Acc:0.9244729957026893|Val Loss:0.09596572071313858|Val Acc:0.9720744680851063\n",
      "Epoch:2|Train Loss:0.0694747051506599|Train Acc:0.9781546208530806|Val Loss:0.06675227184561973|Val Acc:0.9782247340425532\n",
      "Epoch:3|Train Loss:0.05002978890560462|Train Acc:0.98362213669795|Val Loss:0.06574748136831368|Val Acc:0.9805518617021277\n",
      "Epoch:4|Train Loss:0.03945154916733433|Train Acc:0.9870347057897333|Val Loss:0.06790013114693871|Val Acc:0.981216755319149\n",
      "Epoch:5|Train Loss:0.03192989953012334|Train Acc:0.9900585011848341|Val Loss:0.06779796327711975|Val Acc:0.9798869680851063\n",
      "Epoch:6|Train Loss:0.025910181896010704|Train Acc:0.9915395438388626|Val Loss:0.05836796587546098|Val Acc:0.9850398936170213\n",
      "Epoch:7|Train Loss:0.023935663322940188|Train Acc:0.991928317535545|Val Loss:0.05189152884958411|Val Acc:0.9850398936170213\n",
      "Epoch:8|Train Loss:0.01990795230009633|Train Acc:0.9935759774881516|Val Loss:0.05808203031978956|Val Acc:0.984375\n",
      "Epoch:9|Train Loss:0.017008175816325143|Train Acc:0.994372037914692|Val Loss:0.058914484416550776|Val Acc:0.9833776595744681\n",
      "Epoch:10|Train Loss:0.015909737430654148|Train Acc:0.9947608116113744|Val Loss:0.059398194312729795|Val Acc:0.984375\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    train_loss,train_acc=train(model,device,train_iterator,optimizer,criterion)\n",
    "    valid_loss,valid_acc=evaluate(model,device,valid_iterator,criterion)\n",
    "    if valid_loss<best_valid_loss:#如果是最好的模型就保存到文件夹\n",
    "        best_valid_loss=valid_loss\n",
    "        torch.save(model.state_dict(),model_path)\n",
    "    print('Epoch:{0}|Train Loss:{1}|Train Acc:{2}|Val Loss:{3}|Val Acc:{4}'.format(epoch+1,train_loss,train_acc,valid_loss,valid_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 0.034779636307981365 | Test Acc: 0.9883558917197452 |\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "test_loss, test_acc = evaluate(model, device, test_iterator, criterion)\n",
    "\n",
    "print('| Test Loss: {0} | Test Acc: {1} |'.format(test_loss,test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.set_num_threads(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_trans_alexnet = transforms.Compose([\n",
    "    transforms.Resize(227),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,),(0.3081,))#参数mean和std来自于训练集，但是transform本身会在训练和评测的时候都会使用\n",
    "])\n",
    "train_data = datasets.MNIST('data',train=True,download=True,transform=data_trans_alexnet)\n",
    "test_data = datasets.MNIST('data',train=False,download=True,transform=data_trans_alexnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train=int(len(train_data)*0.9)\n",
    "n_validation=len(train_data)-n_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,valid_data=torch.utils.data.random_split(train_data,[n_train,n_validation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54000 6000 10000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data),len(valid_data),len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator=torch.utils.data.DataLoader(train_data,shuffle=True,batch_size=batch_size)\n",
    "valid_iterator=torch.utils.data.DataLoader(valid_data,batch_size=batch_size)\n",
    "test_iterator=torch.utils.data.DataLoader(test_data,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self):#init函数定义的是网络的架构、关键的网络模块、模组\n",
    "        super(AlexNet,self).__init__()\n",
    "        self.feature_block=nn.Sequential(\n",
    "            nn.Conv2d(1,64,kernel_size=11,stride=4,padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3,stride=2),\n",
    "            nn.Conv2d(64,192,kernel_size=5,padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3,stride=2),\n",
    "            nn.Conv2d(192,384,kernel_size=3,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384,256,kernel_size=3,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256,256,kernel_size=3,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3,stride=2)\n",
    "        )\n",
    "        self.avgpool=nn.AdaptiveAvgPool2d((6,6))\n",
    "        self.class_block=nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256*6*6,4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096,4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096,10),\n",
    "        )\n",
    "    def forward(self,x):#数据的正向流\n",
    "        x = self.feature_block(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0),256*6*6)\n",
    "        x = self.class_block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AlexNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.device_count() > 1:\n",
    "    model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): AlexNet(\n",
       "    (feature_block): Sequential(\n",
       "      (0): Conv2d(1, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "      (1): ReLU(inplace)\n",
       "      (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (4): ReLU(inplace)\n",
       "      (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (7): ReLU(inplace)\n",
       "      (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (9): ReLU(inplace)\n",
       "      (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): ReLU(inplace)\n",
       "      (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "    (class_block): Sequential(\n",
       "      (0): Dropout(p=0.5)\n",
       "      (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "      (2): ReLU(inplace)\n",
       "      (3): Dropout(p=0.5)\n",
       "      (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "      (5): ReLU(inplace)\n",
       "      (6): Linear(in_features=4096, out_features=10, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=10\n",
    "model_dir='models'\n",
    "model_path=os.path.join(model_dir,'alexnet_mnist.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_valid_loss=float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1|Train Loss:0.32351489656415033|Train Acc:0.8941424763033176|Val Loss:0.07242300928114577|Val Acc:0.979332890282286\n",
      "Epoch:2|Train Loss:0.09779548081370751|Train Acc:0.972477290726386|Val Loss:0.10621865283935628|Val Acc:0.9686945924099456\n",
      "Epoch:3|Train Loss:0.08353047891215408|Train Acc:0.9770561809082167|Val Loss:0.05300462175596585|Val Acc:0.984375\n",
      "Epoch:4|Train Loss:0.07058588084566156|Train Acc:0.9801848835148518|Val Loss:0.04931169888500045|Val Acc:0.9858710106382979\n",
      "Epoch:5|Train Loss:0.06481341558389402|Train Acc:0.9818572274881516|Val Loss:0.04368885833661052|Val Acc:0.988530585106383\n",
      "Epoch:6|Train Loss:0.06335728050908074|Train Acc:0.9819683056872038|Val Loss:0.0384771905720551|Val Acc:0.9896387413461157\n",
      "Epoch:7|Train Loss:0.05232932414060626|Train Acc:0.9853932168246445|Val Loss:0.039285554669480374|Val Acc:0.9905806741815932\n",
      "Epoch:8|Train Loss:0.0590564951982561|Train Acc:0.9838319510503968|Val Loss:0.035191089238109506|Val Acc:0.9903590425531915\n",
      "Epoch:9|Train Loss:0.04876718690654183|Train Acc:0.9865718799603493|Val Loss:0.03700866214831934|Val Acc:0.9920212765957447\n",
      "Epoch:10|Train Loss:0.048491575686212506|Train Acc:0.9866706161137441|Val Loss:0.03971361452119147|Val Acc:0.989804964750371\n",
      "Cost time: 2103.1075785160065 s.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for epoch in range(epochs):\n",
    "    train_loss,train_acc=train(model,device,train_iterator,optimizer,criterion)\n",
    "    valid_loss,valid_acc=evaluate(model,device,valid_iterator,criterion)\n",
    "    if valid_loss<best_valid_loss:  # 如果是最好的模型就保存到文件夹\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(),model_path)\n",
    "    print('Epoch:{0}|Train Loss:{1}|Train Acc:{2}|Val Loss:{3}|Val Acc:{4}'.format(epoch+1,train_loss,train_acc,valid_loss,valid_acc))\n",
    "end = time.time()\n",
    "print(\"Cost time: {} s.\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 0.03559933172147365 | Test Acc: 0.9906449044585988 |\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(model_path))\n",
    "test_loss, test_acc = evaluate(model, device, test_iterator, criterion)\n",
    "print('| Test Loss: {0} | Test Acc: {1} |'.format(test_loss,test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGGBlock(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,batch_norm):#在后来改良后的VGG网络增加了BatchNorm\n",
    "        super(VGGBlock,self).__init__()\n",
    "        stack=[]\n",
    "        stack.append(nn.Conv2d(in_channels,out_channels,kernel_size=3,padding=1))\n",
    "        if batch_norm:\n",
    "            stack.append(nn.BatchNorm2d(out_channels))\n",
    "        stack.append(nn.ReLU(inplace=True))\n",
    "        self.model_block=nn.Sequential(*stack)\n",
    "    def forward(self,x):\n",
    "        return self.model_block(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGGNet11(nn.Module):\n",
    "    def __init__(self,block,pool,batch_norm):#block是一个网络模组抽象，pool也是pooling层的抽象\n",
    "        super(VGGNet11,self).__init__()\n",
    "        self.feature_block=nn.Sequential(\n",
    "            block(1,64,batch_norm), #32*32\n",
    "            pool(kernel_size=2,stride=2),#16*16\n",
    "            block(64,128,batch_norm),\n",
    "            pool(kernel_size=2,stride=2),#8*8\n",
    "            block(128,256,batch_norm),\n",
    "            block(256,256,batch_norm),\n",
    "            pool(kernel_size=2,stride=2),#4*4\n",
    "            block(256,512,batch_norm),\n",
    "            block(512,512,batch_norm),\n",
    "            pool(kernel_size=2,stride=2),#2*2\n",
    "            block(512,512,batch_norm),\n",
    "            block(512,512,batch_norm),\n",
    "            pool(kernel_size=2,stride=2),#1*1\n",
    "        )\n",
    "        self.classifier=nn.Linear(512,10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=self.feature_block(x)\n",
    "        x=x.view(x.shape[0],-1)\n",
    "        x=self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGGNet16(nn.Module):\n",
    "    def __init__(self,block,pool,batch_norm): #block是一个网络模组抽象，pool也是pooling层的抽象\n",
    "        super(VGGNet16,self).__init__()\n",
    "        self.feature_block=nn.Sequential(\n",
    "            block(1,64,batch_norm), #32*32\n",
    "            block(64,64,batch_norm), #32*32\n",
    "            pool(kernel_size=2,stride=2),#16*16\n",
    "            block(64,128,batch_norm),\n",
    "            block(128,128,batch_norm),\n",
    "            pool(kernel_size=2,stride=2),#8*8\n",
    "            block(128,256,batch_norm),\n",
    "            block(256,256,batch_norm),\n",
    "            pool(kernel_size=2,stride=2),#4*4\n",
    "            block(256,512,batch_norm),\n",
    "            block(512,512,batch_norm),\n",
    "            block(512,512,batch_norm),\n",
    "            pool(kernel_size=2,stride=2),#2*2\n",
    "            block(512,512,batch_norm),\n",
    "            block(512,512,batch_norm),\n",
    "            block(512,512,batch_norm),\n",
    "            pool(kernel_size=2,stride=2),#1*1\n",
    "        )\n",
    "        self.classifier=nn.Linear(512,10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=self.feature_block(x)\n",
    "        x=x.view(x.shape[0],-1)\n",
    "        x=self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timer(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start = time.time()\n",
    "        func(*args,**kwargs)\n",
    "        end = time.time()\n",
    "        cost = end - start\n",
    "        print(\"Cost time: {} mins.\".format(cost/60)) \n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timer\n",
    "def train_fit():\n",
    "    best_valid_loss = float('inf')\n",
    "    info = 'Epoch:{0} | Train Loss:{1} | Train Acc:{2} | Val Loss:{3} | Val Acc:{4}'\n",
    "    for epoch in range(epochs):\n",
    "        train_loss, train_acc = train(model, device, train_iterator, optimizer, criterion)\n",
    "        valid_loss, valid_acc = evaluate(model, device, valid_iterator, criterion)\n",
    "        if valid_loss < best_valid_loss:  # 如果是最好的模型就保存到文件夹\n",
    "            best_valid_loss = valid_loss\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "        print(info.format(epoch+1, train_loss, train_acc, valid_loss, valid_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGGNet16(VGGBlock, nn.MaxPool2d, True)\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu:0')\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = nn.DataParallel(model)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): VGGNet16(\n",
       "    (feature_block): Sequential(\n",
       "      (0): VGGBlock(\n",
       "        (model_block): Sequential(\n",
       "          (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (1): VGGBlock(\n",
       "        (model_block): Sequential(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (3): VGGBlock(\n",
       "        (model_block): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (4): VGGBlock(\n",
       "        (model_block): Sequential(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (6): VGGBlock(\n",
       "        (model_block): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (7): VGGBlock(\n",
       "        (model_block): Sequential(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (9): VGGBlock(\n",
       "        (model_block): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (10): VGGBlock(\n",
       "        (model_block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (11): VGGBlock(\n",
       "        (model_block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (12): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (13): VGGBlock(\n",
       "        (model_block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (14): VGGBlock(\n",
       "        (model_block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (15): VGGBlock(\n",
       "        (model_block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())   # 优化器\n",
    "criterion = nn.CrossEntropyLoss()    # loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "model_path = os.path.join(model_dir,'vggnet16_mnist.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1 | Train Loss:0.19393341220535726 | Train Acc:0.9390612658448694 | Val Loss:0.07097932977720778 | Val Acc:0.9781139188624443\n",
      "Epoch:2 | Train Loss:0.06113600740165084 | Train Acc:0.982912470379147 | Val Loss:0.04401426494834905 | Val Acc:0.988530585106383\n",
      "Epoch:3 | Train Loss:0.04657110462177068 | Train Acc:0.9873432563661964 | Val Loss:0.040046898965188794 | Val Acc:0.9875886529049975\n",
      "Epoch:4 | Train Loss:0.03594857168061685 | Train Acc:0.9899967910977902 | Val Loss:0.03436292640547803 | Val Acc:0.9915226063829787\n",
      "Epoch:5 | Train Loss:0.0333620997722883 | Train Acc:0.9907064573459715 | Val Loss:0.033263351282778575 | Val Acc:0.9906914893617021\n",
      "Epoch:6 | Train Loss:0.0272576184391587 | Train Acc:0.9925145636096385 | Val Loss:0.04149616933724982 | Val Acc:0.9891954787234043\n",
      "Epoch:7 | Train Loss:0.024179436739531934 | Train Acc:0.9930576125592417 | Val Loss:0.04127165740554003 | Val Acc:0.9893062945376051\n",
      "Epoch:8 | Train Loss:0.02496145206384396 | Train Acc:0.9933353080568721 | Val Loss:0.04908663307891247 | Val Acc:0.9901374115588817\n",
      "Epoch:9 | Train Loss:0.019500640461494995 | Train Acc:0.9945201421800948 | Val Loss:0.04320783102686735 | Val Acc:0.9893062945376051\n",
      "Epoch:10 | Train Loss:0.01773022176734816 | Train Acc:0.9951680983412322 | Val Loss:0.03947758831163036 | Val Acc:0.9901374115588817\n",
      "Cost time: 48.601798272132875 mins.\n"
     ]
    }
   ],
   "source": [
    "train_fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 0.029480772674273535 | Test Acc: 0.9918391719745223 |\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(model_path))\n",
    "test_loss, test_acc = evaluate(model, device, test_iterator, criterion)\n",
    "print('| Test Loss: {0} | Test Acc: {1} |'.format(test_loss,test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.get_num_threads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
