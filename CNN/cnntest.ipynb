{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mnist手写数字识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-c651a1ed2de4>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /root/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /root/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /root/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /root/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ./MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /root/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "# 如果MNIST_data不存在会先下载再读入，pytorch的数据集和这个不一样。\n",
    "mnist = input_data.read_data_sets('./MNIST_data',one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 28*28*1 灰度图被拉成一行了\n",
    "mnist.train.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 784)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 验证集\n",
    "mnist.validation.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 循环读，共55000张\n",
    "train_x,train_y = mnist.train.next_batch(20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 784)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试集\n",
    "test_x, test_y = mnist.test.next_batch(5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 图像的可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rc('image',cmap='binary')\n",
    "for i in range(10):#打印10张图\n",
    "    plt.subplot(2,5,i+1)\n",
    "    # 打印图用imshow\n",
    "    plt.imshow(train_x[i].reshape(28,28))\n",
    "    print(train_y[i])\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "plt.tight_layout()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 全连接神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Sequential 相当于pipeline，会自动执行forward和bp\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model1():\n",
    "    model=Sequential()\n",
    "    model.add(Dense(784,activation='relu'))\n",
    "    model.add(Dense(100,activation='relu'))\n",
    "    model.add(Dense(100,activation='relu'))\n",
    "    model.add(Dense(10,activation='softmax'))\n",
    "    model.compile(optimizer='adam',loss='categorical_crossentropy')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = model1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 10s 507us/step - loss: 0.3189\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 9s 451us/step - loss: 0.1244\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 9s 467us/step - loss: 0.0849\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 9s 458us/step - loss: 0.0579\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 9s 460us/step - loss: 0.0424\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 9s 456us/step - loss: 0.0365\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 9s 460us/step - loss: 0.0360\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 9s 455us/step - loss: 0.0287\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 9s 454us/step - loss: 0.0231\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 10s 480us/step - loss: 0.0180\n"
     ]
    }
   ],
   "source": [
    "history = m.fit(train_x,train_y,epochs=10,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = m.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9716"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(pred.argmax(1),test_y.argmax(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 卷积神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import random\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir='models'\n",
    "if not os.path.isdir(model_dir):\n",
    "    os.makedirs(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不像TensorFlow一样有GPU和CPU版本，安装的时候pytorch会自动识别CPU还是GPU\n",
    "import torch\n",
    "# nn就是各种层\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# optim是优化器\n",
    "import torch.optim as optim\n",
    "# torchvision有optim的一些东西\n",
    "import torchvision\n",
    "# trainsforms相当于pipeline\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 定一个transforms\n",
    "# # compose相当于一个pipeline，链式调用\n",
    "# data_trans = transforms.Compose([\n",
    "#     transforms.Resize(32),   # resize是防止在多层网络中图像提前变成1*1\n",
    "#     transforms.ToTensor()\n",
    "# #    transforms.Normalize(()())?<-参数mean和std来自于训练集，但是transform本身会在训练和评测的时候都会使用\n",
    "# ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 图像的Normalize\n",
    "\n",
    "- 目的：将图片进行归一化的缩放|(x-mean)/std\n",
    "    - 如果不归一化，可能导致梯度爆炸或者梯度衰减、梯度为零。矩阵是相乘的，网络越深，连乘越多。如果梯度都大于1就会越乘越大，导致梯度爆炸，上溢出；如果梯度小于1，会越来越小，最终导致梯度为0，梯度离散，相当于平滩底部，学不到什么东西。\n",
    "\n",
    "- 思考：图片归一化后，真的不存在小于0或者大于1的outlier了吗？\n",
    "    - 不一定，如果数据不均匀，可能导致小于0或者大于1的数据。归一化的公式？\n",
    "\n",
    "- 思考：归一化哪部分数据？\n",
    "    - A 训练集 B 评测集 C 训练集+评测集？     A\n",
    "    - 不可能得到全部数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13070032"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(mnist.train.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30815914"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(mnist.train.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_trans = transforms.Compose([\n",
    "    transforms.Resize(32),   # 防止提前出现1*1像素的图像\n",
    "    transforms.ToTensor(),   # 数据结构转换成torch能接收的\n",
    "    transforms.Normalize((0.1307,),(0.3081,))  # 参数mean和std来自于训练集，但是transform本身会在训练和评测的时候都会使用\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 会建立一个data目录，train是否是训练集。\n",
    "train_data = datasets.MNIST('data', train=True, download=True, transform=data_trans)\n",
    "test_data = datasets.MNIST('data', train=False, download=True, transform=data_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = int(len(train_data)*0.9)\n",
    "n_validation = len(train_data)-n_train    # 10%做评测集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,valid_data = torch.utils.data.random_split(train_data,[n_train,n_validation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54000 6000 10000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data),len(valid_data),len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 目前完成了数据集的制作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterator 相当于pytorch里面的一个object，对数据进行切分之后的数据结构。只有训练集有必要shuffle。\n",
    "train_iterator=torch.utils.data.DataLoader(train_data,shuffle=True,batch_size=batch_size)\n",
    "valid_iterator=torch.utils.data.DataLoader(valid_data,batch_size=batch_size)\n",
    "test_iterator=torch.utils.data.DataLoader(test_data,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet,self).__init__()\n",
    "        #第一层conv1卷积层，in_channel=1,output_channel=6,kernel_size=5*5,input_size=32*32,output_size=28*28\n",
    "        self.conv1=nn.Conv2d(1,6,5)\n",
    "        #第二层conv2，output_channel=6 ,kernel 5*5,output_size=10*10,input_size=14*14\n",
    "        self.conv2=nn.Conv2d(6,16,5)\n",
    "        self.fc1=nn.Linear(16*5*5,120)\n",
    "        self.fc2=nn.Linear(120,80)\n",
    "        self.fc3=nn.Linear(80,10)#不用增加softmax层，在cross_entropy的Loss中自动增加了Softmax\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=F.max_pool2d(F.relu(self.conv1(x)),2)\n",
    "        x=F.max_pool2d(F.relu(self.conv2(x)),2)\n",
    "        x=x.view(x.shape[0],-1)  #？\n",
    "        x=F.relu(self.fc1(x))\n",
    "        x=F.relu(self.fc2(x))\n",
    "        x=self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 到此神经网络定义完毕\n",
    "\n",
    "## 载入模型并训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=LeNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeNet(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=80, bias=True)\n",
       "  (fc3): Linear(in_features=80, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=optim.Adam(model.parameters())   # 优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=nn.CrossEntropyLoss()    # loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 如何评价\n",
    "- 计算精确度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accu(fx,y):\n",
    "    pred=fx.max(1,keepdim=True)[1]\n",
    "    correct=pred.eq(y.view_as(pred)).sum()#得到该batch的准确度\n",
    "    acc=correct.float()/pred.shape[0]\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,device,iterator,optimizer,criterion):\n",
    "    epoch_loss=0#积累变量\n",
    "    epoch_acc=0#积累变量\n",
    "    model.train()#该函数表示PHASE=Train\n",
    "    \n",
    "    for (x,y) in iterator:#拿去每一个minibatch\n",
    "        x=x.to(device)\n",
    "        y=y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        fx=model(x)#进行forward\n",
    "        loss=criterion(fx,y)#计算Loss,train_loss\n",
    "        type(loss)\n",
    "        acc=accu(fx,y)#计算精确度，train_accu\n",
    "        loss.backward()#进行BP\n",
    "        optimizer.step()#统一更新模型\n",
    "        epoch_loss+=loss.item()\n",
    "        epoch_acc+=acc.item()\n",
    "        \n",
    "    return epoch_loss/len(iterator),epoch_acc/len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model,device,iterator,criterion):\n",
    "    epoch_loss=0\n",
    "    epoch_acc=0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for (x,y) in iterator:\n",
    "            x=x.to(device)\n",
    "            y=y.to(device)\n",
    "            fx=model(x)\n",
    "            loss=criterion(fx,y)\n",
    "            acc=accu(fx,y)\n",
    "            epoch_loss+=loss.item()\n",
    "            epoch_acc+=acc.item()\n",
    "    return epoch_loss/len(iterator),epoch_acc/len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=10\n",
    "model_path=os.path.join(model_dir,'lenet_mnist.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_valid_loss=float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1|Train Loss:0.24576564233140993|Train Acc:0.9252443720379147|Val Loss:0.10026893629989725|Val Acc:0.9699689714198417\n",
      "Epoch:2|Train Loss:0.07282023004287086|Train Acc:0.9774387835467596|Val Loss:0.058544988308022634|Val Acc:0.982491134963137\n",
      "Epoch:3|Train Loss:0.05119644594047731|Train Acc:0.9840355944153257|Val Loss:0.057960785568711606|Val Acc:0.9812721629092034\n",
      "Epoch:4|Train Loss:0.03853387127837864|Train Acc:0.987509873594153|Val Loss:0.05738091207248099|Val Acc:0.982491134963137\n",
      "Epoch:5|Train Loss:0.030649784546327816|Train Acc:0.9901880924170616|Val Loss:0.04693268120605895|Val Acc:0.9859264182283524\n",
      "Epoch:6|Train Loss:0.02556110729388363|Train Acc:0.9915580568720379|Val Loss:0.055865582276849034|Val Acc:0.9846520392184562\n",
      "Epoch:7|Train Loss:0.023265178518378622|Train Acc:0.9920332247470792|Val Loss:0.04867440676118465|Val Acc:0.9862034574468085\n",
      "Epoch:8|Train Loss:0.019254651971126056|Train Acc:0.9937611078199052|Val Loss:0.04479673015389671|Val Acc:0.9874224288666502\n",
      "Epoch:9|Train Loss:0.018177559477899452|Train Acc:0.9940202902843602|Val Loss:0.04437024752668878|Val Acc:0.9887522161006927\n",
      "Epoch:10|Train Loss:0.013812969307695468|Train Acc:0.9955568720379147|Val Loss:0.05351789929765336|Val Acc:0.9868683510638298\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    train_loss,train_acc=train(model,device,train_iterator,optimizer,criterion)\n",
    "    valid_loss,valid_acc=evaluate(model,device,valid_iterator,criterion)\n",
    "    if valid_loss<best_valid_loss:#如果是最好的模型就保存到文件夹\n",
    "        best_valid_loss=valid_loss\n",
    "        torch.save(model.state_dict(),model_path)\n",
    "    print('Epoch:{0}|Train Loss:{1}|Train Acc:{2}|Val Loss:{3}|Val Acc:{4}'.format(epoch+1,train_loss,train_acc,valid_loss,valid_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 0.03467386759295585 | Test Acc: 0.9895501592356688 |\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "test_loss, test_acc = evaluate(model, device, test_iterator, criterion)\n",
    "\n",
    "print('| Test Loss: {0} | Test Acc: {1} |'.format(test_loss,test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_num_threads(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_trans_alexnet = transforms.Compose([\n",
    "    transforms.Resize(227),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,),(0.3081,))#参数mean和std来自于训练集，但是transform本身会在训练和评测的时候都会使用\n",
    "])\n",
    "train_data = datasets.MNIST('data',train=True,download=True,transform=data_trans_alexnet)\n",
    "test_data = datasets.MNIST('data',train=False,download=True,transform=data_trans_alexnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train=int(len(train_data)*0.9)\n",
    "n_validation=len(train_data)-n_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,valid_data=torch.utils.data.random_split(train_data,[n_train,n_validation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54000 6000 10000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data),len(valid_data),len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator=torch.utils.data.DataLoader(train_data,shuffle=True,batch_size=batch_size)\n",
    "valid_iterator=torch.utils.data.DataLoader(valid_data,batch_size=batch_size)\n",
    "test_iterator=torch.utils.data.DataLoader(test_data,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self):#init函数定义的是网络的架构、关键的网络模块、模组\n",
    "        super(AlexNet,self).__init__()\n",
    "        self.feature_block=nn.Sequential(\n",
    "            nn.Conv2d(1,64,kernel_size=11,stride=4,padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3,stride=2),\n",
    "            nn.Conv2d(64,192,kernel_size=5,padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3,stride=2),\n",
    "            nn.Conv2d(192,384,kernel_size=3,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384,256,kernel_size=3,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256,256,kernel_size=3,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3,stride=2)\n",
    "        )\n",
    "        self.avgpool=nn.AdaptiveAvgPool2d((6,6))\n",
    "        self.class_block=nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256*6*6,4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096,4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096,10),\n",
    "        )\n",
    "    def forward(self,x):#数据的正向流\n",
    "        x = self.feature_block(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0),256*6*6)\n",
    "        x = self.class_block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AlexNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (feature_block): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (class_block): Sequential(\n",
       "    (0): Dropout(p=0.5)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace)\n",
       "    (3): Dropout(p=0.5)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace)\n",
       "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=10\n",
    "model_dir='models'\n",
    "model_path=os.path.join(model_dir,'alexnet_mnist.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_valid_loss=float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1|Train Loss:0.30664038052561726|Train Acc:0.8991595082938388|Val Loss:0.08289378956752888|Val Acc:0.9756205671645225\n",
      "Epoch:2|Train Loss:0.10010198266929572|Train Acc:0.971187549391629|Val Loss:0.06561374834718857|Val Acc:0.9792774820581396\n",
      "Epoch:3|Train Loss:0.08785877900939629|Train Acc:0.9756491903868897|Val Loss:0.04346287076143508|Val Acc:0.9876440604950519\n",
      "Epoch:4|Train Loss:0.07618335289527525|Train Acc:0.9781484498655627|Val Loss:0.06057419275191236|Val Acc:0.9832668437602672\n",
      "Epoch:5|Train Loss:0.06757545198636103|Train Acc:0.9812524683808829|Val Loss:0.04482662555900343|Val Acc:0.9863696808510638\n",
      "Epoch:6|Train Loss:0.06108327877985852|Train Acc:0.9829803515243304|Val Loss:0.050641411875790736|Val Acc:0.9870899820581396\n",
      "Epoch:7|Train Loss:0.05734411653426975|Train Acc:0.9843935130331753|Val Loss:0.041215979949908055|Val Acc:0.9876994680851063\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-ba5819ce1510>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_acc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_iterator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalid_loss\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mbest_valid_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m#如果是最好的模型就保存到文件夹\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mbest_valid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-43-82d08a2de87a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, iterator, optimizer, criterion)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mfx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#进行forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#计算Loss,train_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-56-6b850bea8295>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavgpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/dropout.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m    747\u001b[0m     return (_VF.dropout_(input, p, training)\n\u001b[1;32m    748\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m             else _VF.dropout(input, p, training))\n\u001b[0m\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    train_loss,train_acc=train(model,device,train_iterator,optimizer,criterion)\n",
    "    valid_loss,valid_acc=evaluate(model,device,valid_iterator,criterion)\n",
    "    if valid_loss<best_valid_loss:#如果是最好的模型就保存到文件夹\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(),model_path)\n",
    "    print('Epoch:{0}|Train Loss:{1}|Train Acc:{2}|Val Loss:{3}|Val Acc:{4}'.format(epoch+1,train_loss,train_acc,valid_loss,valid_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(model_path))\n",
    "test_loss, test_acc = evaluate(model, device, test_iterator, criterion)\n",
    "print('| Test Loss: {0} | Test Acc: {1} |'.format(test_loss,test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchvision.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.get_num_threads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
