{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mnist手写数字识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-c651a1ed2de4>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /root/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /root/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /root/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /root/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ./MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /root/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "# 如果MNIST_data不存在会先下载再读入，pytorch的数据集和这个不一样。\n",
    "mnist = input_data.read_data_sets('./MNIST_data',one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 28*28*1 灰度图被拉成一行了\n",
    "mnist.train.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 784)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 验证集\n",
    "mnist.validation.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 循环读，共55000张\n",
    "train_x,train_y = mnist.train.next_batch(20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 784)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试集\n",
    "test_x, test_y = mnist.test.next_batch(5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 图像的可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rc('image',cmap='binary')\n",
    "for i in range(10):#打印10张图\n",
    "    plt.subplot(2,5,i+1)\n",
    "    # 打印图用imshow\n",
    "    plt.imshow(train_x[i].reshape(28,28))\n",
    "    print(train_y[i])\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "plt.tight_layout()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 全连接神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Sequential 相当于pipeline，会自动执行forward和bp\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model1():\n",
    "    model=Sequential()\n",
    "    \n",
    "    model.add(Dense(100,input_shape=(784,), activation='relu'))\n",
    "#     model.add(Dense(100,activation='relu'))\n",
    "    model.add(Dense(100,activation='relu'))\n",
    "    model.add(Dense(10,activation='softmax'))\n",
    "    model.compile(optimizer='adam',loss='categorical_crossentropy')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = model1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 89,610\n",
      "Trainable params: 89,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 8s 383us/step - loss: 0.4145\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 5s 269us/step - loss: 0.1664\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 5s 271us/step - loss: 0.1151\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 5s 271us/step - loss: 0.0817\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 5s 268us/step - loss: 0.0597\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 5s 268us/step - loss: 0.0453\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 5s 266us/step - loss: 0.0363\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 5s 266us/step - loss: 0.0327\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 5s 267us/step - loss: 0.0215\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 5s 267us/step - loss: 0.0197\n"
     ]
    }
   ],
   "source": [
    "history = m.fit(train_x,train_y,epochs=10,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = m.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(pred.argmax(1),test_y.argmax(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 卷积神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import time\n",
    "import random\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir='models'\n",
    "if not os.path.isdir(model_dir):\n",
    "    os.makedirs(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不像TensorFlow一样有GPU和CPU版本，安装的时候pytorch会自动识别CPU还是GPU\n",
    "import torch\n",
    "# nn就是各种层\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# optim是优化器\n",
    "import torch.optim as optim\n",
    "# torchvision有optim的一些东西\n",
    "import torchvision\n",
    "# trainsforms相当于pipeline\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 定一个transforms\n",
    "# # compose相当于一个pipeline，链式调用\n",
    "# data_trans = transforms.Compose([\n",
    "#     transforms.Resize(32),   # resize是防止在多层网络中图像提前变成1*1\n",
    "#     transforms.ToTensor()\n",
    "# #    transforms.Normalize(()())?<-参数mean和std来自于训练集，但是transform本身会在训练和评测的时候都会使用\n",
    "# ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 图像的Normalize\n",
    "\n",
    "- 目的：将图片进行归一化的缩放|(x-mean)/std\n",
    "    - 如果不归一化，可能导致梯度爆炸或者梯度衰减、梯度为零。矩阵是相乘的，网络越深，连乘越多。如果梯度都大于1就会越乘越大，导致梯度爆炸，上溢出；如果梯度小于1，会越来越小，最终导致梯度为0，梯度离散，相当于平滩底部，学不到什么东西。\n",
    "\n",
    "- 思考：图片归一化后，真的不存在小于0或者大于1的outlier了吗？\n",
    "    - 不一定，如果数据不均匀，可能导致小于0或者大于1的数据。归一化的公式？\n",
    "\n",
    "- 思考：归一化哪部分数据？\n",
    "    - A 训练集 B 评测集 C 训练集+评测集？     A\n",
    "    - 不可能得到全部数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13070044"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(mnist.train.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30815923"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(mnist.train.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_trans = transforms.Compose([\n",
    "    transforms.Resize(32),   # 防止提前出现1*1像素的图像\n",
    "    transforms.ToTensor(),   # 数据结构转换成torch能接收的\n",
    "    transforms.Normalize((0.1307,),(0.3081,))  # 参数mean和std来自于训练集，但是transform本身会在训练和评测的时候都会使用\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 会建立一个data目录，train是否是训练集。\n",
    "train_data = datasets.MNIST('data', train=True, download=True, transform=data_trans)\n",
    "test_data = datasets.MNIST('data', train=False, download=True, transform=data_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = int(len(train_data)*0.9)\n",
    "n_validation = len(train_data)-n_train    # 10%做评测集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,valid_data = torch.utils.data.random_split(train_data,[n_train,n_validation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54000 6000 10000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data),len(valid_data),len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 目前完成了数据集的制作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterator 相当于pytorch里面的一个object，对数据进行切分之后的数据结构。只有训练集有必要shuffle。\n",
    "train_iterator=torch.utils.data.DataLoader(train_data,shuffle=True,batch_size=batch_size)\n",
    "valid_iterator=torch.utils.data.DataLoader(valid_data,batch_size=batch_size)\n",
    "test_iterator=torch.utils.data.DataLoader(test_data,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet,self).__init__()\n",
    "        #第一层conv1卷积层，in_channel=1,output_channel=6,kernel_size=5*5,input_size=32*32,output_size=28*28\n",
    "        self.conv1=nn.Conv2d(1,6,5)\n",
    "        #第二层conv2，output_channel=6 ,kernel 5*5,output_size=10*10,input_size=14*14\n",
    "        self.conv2=nn.Conv2d(6,16,5)\n",
    "        self.fc1=nn.Linear(16*5*5,120)\n",
    "        self.fc2=nn.Linear(120,80)\n",
    "        self.fc3=nn.Linear(80,10)#不用增加softmax层，在cross_entropy的Loss中自动增加了Softmax\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=F.max_pool2d(F.relu(self.conv1(x)),2)\n",
    "        x=F.max_pool2d(F.relu(self.conv2(x)),2)\n",
    "        x=x.view(x.shape[0],-1)  #？\n",
    "        x=F.relu(self.fc1(x))\n",
    "        x=F.relu(self.fc2(x))\n",
    "        x=self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 到此神经网络定义完毕\n",
    "\n",
    "## 载入模型并训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=LeNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeNet(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=80, bias=True)\n",
       "  (fc3): Linear(in_features=80, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-01e6a7db4b03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# 优化器\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "optimizer=optim.Adam(model.parameters())   # 优化器\n",
    "criterion=nn.CrossEntropyLoss()    # loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=nn.CrossEntropyLoss()    # loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 如何评价\n",
    "- 计算精确度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accu(fx,y):\n",
    "    pred=fx.max(1,keepdim=True)[1]\n",
    "    correct=pred.eq(y.view_as(pred)).sum()#得到该batch的准确度\n",
    "    acc=correct.float()/pred.shape[0]\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,device,iterator,optimizer,criterion):\n",
    "    epoch_loss=0  #积累变量\n",
    "    epoch_acc=0   #积累变量\n",
    "    model.train() #该函数表示PHASE=Train\n",
    "    \n",
    "    for (x,y) in iterator:#拿去每一个minibatch\n",
    "        x=x.to(device)\n",
    "        y=y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        fx=model(x)#进行forward\n",
    "        loss=criterion(fx,y)#计算Loss,train_loss\n",
    "        type(loss)\n",
    "        acc=accu(fx,y)#计算精确度，train_accu\n",
    "        loss.backward()#进行BP\n",
    "        optimizer.step()#统一更新模型\n",
    "        epoch_loss+=loss.item()\n",
    "        epoch_acc+=acc.item()\n",
    "        \n",
    "    return epoch_loss/len(iterator),epoch_acc/len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model,device,iterator,criterion):\n",
    "    epoch_loss=0\n",
    "    epoch_acc=0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for (x,y) in iterator:\n",
    "            x=x.to(device)\n",
    "            y=y.to(device)\n",
    "            fx=model(x)\n",
    "            loss=criterion(fx,y)\n",
    "            acc=accu(fx,y)\n",
    "            epoch_loss+=loss.item()\n",
    "            epoch_acc+=acc.item()\n",
    "    return epoch_loss/len(iterator),epoch_acc/len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=10\n",
    "model_path=os.path.join(model_dir,'lenet_mnist.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_valid_loss=float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1|Train Loss:0.23972646112584672|Train Acc:0.9244729957026893|Val Loss:0.09596572071313858|Val Acc:0.9720744680851063\n",
      "Epoch:2|Train Loss:0.0694747051506599|Train Acc:0.9781546208530806|Val Loss:0.06675227184561973|Val Acc:0.9782247340425532\n",
      "Epoch:3|Train Loss:0.05002978890560462|Train Acc:0.98362213669795|Val Loss:0.06574748136831368|Val Acc:0.9805518617021277\n",
      "Epoch:4|Train Loss:0.03945154916733433|Train Acc:0.9870347057897333|Val Loss:0.06790013114693871|Val Acc:0.981216755319149\n",
      "Epoch:5|Train Loss:0.03192989953012334|Train Acc:0.9900585011848341|Val Loss:0.06779796327711975|Val Acc:0.9798869680851063\n",
      "Epoch:6|Train Loss:0.025910181896010704|Train Acc:0.9915395438388626|Val Loss:0.05836796587546098|Val Acc:0.9850398936170213\n",
      "Epoch:7|Train Loss:0.023935663322940188|Train Acc:0.991928317535545|Val Loss:0.05189152884958411|Val Acc:0.9850398936170213\n",
      "Epoch:8|Train Loss:0.01990795230009633|Train Acc:0.9935759774881516|Val Loss:0.05808203031978956|Val Acc:0.984375\n",
      "Epoch:9|Train Loss:0.017008175816325143|Train Acc:0.994372037914692|Val Loss:0.058914484416550776|Val Acc:0.9833776595744681\n",
      "Epoch:10|Train Loss:0.015909737430654148|Train Acc:0.9947608116113744|Val Loss:0.059398194312729795|Val Acc:0.984375\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    train_loss,train_acc=train(model,device,train_iterator,optimizer,criterion)\n",
    "    valid_loss,valid_acc=evaluate(model,device,valid_iterator,criterion)\n",
    "    if valid_loss<best_valid_loss:#如果是最好的模型就保存到文件夹\n",
    "        best_valid_loss=valid_loss\n",
    "        torch.save(model.state_dict(),model_path)\n",
    "    print('Epoch:{0}|Train Loss:{1}|Train Acc:{2}|Val Loss:{3}|Val Acc:{4}'.format(epoch+1,train_loss,train_acc,valid_loss,valid_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 0.034779636307981365 | Test Acc: 0.9883558917197452 |\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "test_loss, test_acc = evaluate(model, device, test_iterator, criterion)\n",
    "\n",
    "print('| Test Loss: {0} | Test Acc: {1} |'.format(test_loss,test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.set_num_threads(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_trans_alexnet = transforms.Compose([\n",
    "    transforms.Resize(227),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,),(0.3081,))#参数mean和std来自于训练集，但是transform本身会在训练和评测的时候都会使用\n",
    "])\n",
    "train_data = datasets.MNIST('data',train=True,download=True,transform=data_trans_alexnet)\n",
    "test_data = datasets.MNIST('data',train=False,download=True,transform=data_trans_alexnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train=int(len(train_data)*0.9)\n",
    "n_validation=len(train_data)-n_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,valid_data=torch.utils.data.random_split(train_data,[n_train,n_validation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54000 6000 10000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data),len(valid_data),len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator=torch.utils.data.DataLoader(train_data,shuffle=True,batch_size=batch_size)\n",
    "valid_iterator=torch.utils.data.DataLoader(valid_data,batch_size=batch_size)\n",
    "test_iterator=torch.utils.data.DataLoader(test_data,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self):#init函数定义的是网络的架构、关键的网络模块、模组\n",
    "        super(AlexNet,self).__init__()\n",
    "        self.feature_block=nn.Sequential(\n",
    "            nn.Conv2d(1,64,kernel_size=11,stride=4,padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3,stride=2),\n",
    "            nn.Conv2d(64,192,kernel_size=5,padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3,stride=2),\n",
    "            nn.Conv2d(192,384,kernel_size=3,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384,256,kernel_size=3,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256,256,kernel_size=3,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3,stride=2)\n",
    "        )\n",
    "        self.avgpool=nn.AdaptiveAvgPool2d((6,6))\n",
    "        self.class_block=nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256*6*6,4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096,4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096,10),\n",
    "        )\n",
    "    def forward(self,x):#数据的正向流\n",
    "        x = self.feature_block(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0),256*6*6)\n",
    "        x = self.class_block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AlexNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.device_count() > 1:\n",
    "    model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): AlexNet(\n",
       "    (feature_block): Sequential(\n",
       "      (0): Conv2d(1, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "      (1): ReLU(inplace)\n",
       "      (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (4): ReLU(inplace)\n",
       "      (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (7): ReLU(inplace)\n",
       "      (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (9): ReLU(inplace)\n",
       "      (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): ReLU(inplace)\n",
       "      (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "    (class_block): Sequential(\n",
       "      (0): Dropout(p=0.5)\n",
       "      (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "      (2): ReLU(inplace)\n",
       "      (3): Dropout(p=0.5)\n",
       "      (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "      (5): ReLU(inplace)\n",
       "      (6): Linear(in_features=4096, out_features=10, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=10\n",
    "model_dir='models'\n",
    "model_path=os.path.join(model_dir,'alexnet_mnist.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_valid_loss=float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1|Train Loss:0.32351489656415033|Train Acc:0.8941424763033176|Val Loss:0.07242300928114577|Val Acc:0.979332890282286\n",
      "Epoch:2|Train Loss:0.09779548081370751|Train Acc:0.972477290726386|Val Loss:0.10621865283935628|Val Acc:0.9686945924099456\n",
      "Epoch:3|Train Loss:0.08353047891215408|Train Acc:0.9770561809082167|Val Loss:0.05300462175596585|Val Acc:0.984375\n",
      "Epoch:4|Train Loss:0.07058588084566156|Train Acc:0.9801848835148518|Val Loss:0.04931169888500045|Val Acc:0.9858710106382979\n",
      "Epoch:5|Train Loss:0.06481341558389402|Train Acc:0.9818572274881516|Val Loss:0.04368885833661052|Val Acc:0.988530585106383\n",
      "Epoch:6|Train Loss:0.06335728050908074|Train Acc:0.9819683056872038|Val Loss:0.0384771905720551|Val Acc:0.9896387413461157\n",
      "Epoch:7|Train Loss:0.05232932414060626|Train Acc:0.9853932168246445|Val Loss:0.039285554669480374|Val Acc:0.9905806741815932\n",
      "Epoch:8|Train Loss:0.0590564951982561|Train Acc:0.9838319510503968|Val Loss:0.035191089238109506|Val Acc:0.9903590425531915\n",
      "Epoch:9|Train Loss:0.04876718690654183|Train Acc:0.9865718799603493|Val Loss:0.03700866214831934|Val Acc:0.9920212765957447\n",
      "Epoch:10|Train Loss:0.048491575686212506|Train Acc:0.9866706161137441|Val Loss:0.03971361452119147|Val Acc:0.989804964750371\n",
      "Cost time: 2103.1075785160065 s.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for epoch in range(epochs):\n",
    "    train_loss,train_acc=train(model,device,train_iterator,optimizer,criterion)\n",
    "    valid_loss,valid_acc=evaluate(model,device,valid_iterator,criterion)\n",
    "    if valid_loss<best_valid_loss:  # 如果是最好的模型就保存到文件夹\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(),model_path)\n",
    "    print('Epoch:{0}|Train Loss:{1}|Train Acc:{2}|Val Loss:{3}|Val Acc:{4}'.format(epoch+1,train_loss,train_acc,valid_loss,valid_acc))\n",
    "end = time.time()\n",
    "print(\"Cost time: {} s.\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 0.03559933172147365 | Test Acc: 0.9906449044585988 |\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(model_path))\n",
    "test_loss, test_acc = evaluate(model, device, test_iterator, criterion)\n",
    "print('| Test Loss: {0} | Test Acc: {1} |'.format(test_loss,test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGGBlock(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,batch_norm):#在后来改良后的VGG网络增加了BatchNorm\n",
    "        super(VGGBlock,self).__init__()\n",
    "        stack=[]\n",
    "        stack.append(nn.Conv2d(in_channels,out_channels,kernel_size=3,padding=1))\n",
    "        if batch_norm:\n",
    "            stack.append(nn.BatchNorm2d(out_channels))\n",
    "        stack.append(nn.ReLU(inplace=True))\n",
    "        self.model_block=nn.Sequential(*stack)\n",
    "    def forward(self,x):\n",
    "        return self.model_block(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGGNet11(nn.Module):\n",
    "    def __init__(self,block,pool,batch_norm):#block是一个网络模组抽象，pool也是pooling层的抽象\n",
    "        super(VGGNet11,self).__init__()\n",
    "        self.feature_block=nn.Sequential(\n",
    "            block(1,64,batch_norm), #32*32\n",
    "            pool(kernel_size=2,stride=2),#16*16\n",
    "            block(64,128,batch_norm),\n",
    "            pool(kernel_size=2,stride=2),#8*8\n",
    "            block(128,256,batch_norm),\n",
    "            block(256,256,batch_norm),\n",
    "            pool(kernel_size=2,stride=2),#4*4\n",
    "            block(256,512,batch_norm),\n",
    "            block(512,512,batch_norm),\n",
    "            pool(kernel_size=2,stride=2),#2*2\n",
    "            block(512,512,batch_norm),\n",
    "            block(512,512,batch_norm),\n",
    "            pool(kernel_size=2,stride=2),#1*1\n",
    "        )\n",
    "        self.classifier=nn.Linear(512,10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=self.feature_block(x)\n",
    "        x=x.view(x.shape[0],-1)\n",
    "        x=self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGGNet16(nn.Module):\n",
    "    def __init__(self,block,pool,batch_norm): #block是一个网络模组抽象，pool也是pooling层的抽象\n",
    "        super(VGGNet16,self).__init__()\n",
    "        self.feature_block=nn.Sequential(\n",
    "            block(1,64,batch_norm), #32*32\n",
    "            block(64,64,batch_norm), #32*32\n",
    "            pool(kernel_size=2,stride=2),#16*16\n",
    "            block(64,128,batch_norm),\n",
    "            block(128,128,batch_norm),\n",
    "            pool(kernel_size=2,stride=2),#8*8\n",
    "            block(128,256,batch_norm),\n",
    "            block(256,256,batch_norm),\n",
    "            pool(kernel_size=2,stride=2),#4*4\n",
    "            block(256,512,batch_norm),\n",
    "            block(512,512,batch_norm),\n",
    "            block(512,512,batch_norm),\n",
    "            pool(kernel_size=2,stride=2),#2*2\n",
    "            block(512,512,batch_norm),\n",
    "            block(512,512,batch_norm),\n",
    "            block(512,512,batch_norm),\n",
    "            pool(kernel_size=2,stride=2),#1*1\n",
    "        )\n",
    "        self.classifier=nn.Linear(512,10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=self.feature_block(x)\n",
    "        x=x.view(x.shape[0],-1)\n",
    "        x=self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timer(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start = time.time()\n",
    "        func(*args,**kwargs)\n",
    "        end = time.time()\n",
    "        cost = end - start\n",
    "        print(\"Cost time: {} mins.\".format(cost/60)) \n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timer\n",
    "def train_fit():\n",
    "    best_valid_loss = float('inf')\n",
    "    info = 'Epoch:{0} | Train Loss:{1} | Train Acc:{2} | Val Loss:{3} | Val Acc:{4}'\n",
    "    for epoch in range(epochs):\n",
    "        train_loss, train_acc = train(model, device, train_iterator, optimizer, criterion)\n",
    "        valid_loss, valid_acc = evaluate(model, device, valid_iterator, criterion)\n",
    "        if valid_loss < best_valid_loss:  # 如果是最好的模型就保存到文件夹\n",
    "            best_valid_loss = valid_loss\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "        print(info.format(epoch+1, train_loss, train_acc, valid_loss, valid_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGGNet16(VGGBlock, nn.MaxPool2d, True)\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu:0')\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = nn.DataParallel(model)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): VGGNet16(\n",
       "    (feature_block): Sequential(\n",
       "      (0): VGGBlock(\n",
       "        (model_block): Sequential(\n",
       "          (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (1): VGGBlock(\n",
       "        (model_block): Sequential(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (3): VGGBlock(\n",
       "        (model_block): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (4): VGGBlock(\n",
       "        (model_block): Sequential(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (6): VGGBlock(\n",
       "        (model_block): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (7): VGGBlock(\n",
       "        (model_block): Sequential(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (9): VGGBlock(\n",
       "        (model_block): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (10): VGGBlock(\n",
       "        (model_block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (11): VGGBlock(\n",
       "        (model_block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (12): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (13): VGGBlock(\n",
       "        (model_block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (14): VGGBlock(\n",
       "        (model_block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (15): VGGBlock(\n",
       "        (model_block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())   # 优化器\n",
    "criterion = nn.CrossEntropyLoss()    # loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "model_path = os.path.join(model_dir,'vggnet16_mnist.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1 | Train Loss:0.19393341220535726 | Train Acc:0.9390612658448694 | Val Loss:0.07097932977720778 | Val Acc:0.9781139188624443\n",
      "Epoch:2 | Train Loss:0.06113600740165084 | Train Acc:0.982912470379147 | Val Loss:0.04401426494834905 | Val Acc:0.988530585106383\n",
      "Epoch:3 | Train Loss:0.04657110462177068 | Train Acc:0.9873432563661964 | Val Loss:0.040046898965188794 | Val Acc:0.9875886529049975\n",
      "Epoch:4 | Train Loss:0.03594857168061685 | Train Acc:0.9899967910977902 | Val Loss:0.03436292640547803 | Val Acc:0.9915226063829787\n",
      "Epoch:5 | Train Loss:0.0333620997722883 | Train Acc:0.9907064573459715 | Val Loss:0.033263351282778575 | Val Acc:0.9906914893617021\n",
      "Epoch:6 | Train Loss:0.0272576184391587 | Train Acc:0.9925145636096385 | Val Loss:0.04149616933724982 | Val Acc:0.9891954787234043\n",
      "Epoch:7 | Train Loss:0.024179436739531934 | Train Acc:0.9930576125592417 | Val Loss:0.04127165740554003 | Val Acc:0.9893062945376051\n",
      "Epoch:8 | Train Loss:0.02496145206384396 | Train Acc:0.9933353080568721 | Val Loss:0.04908663307891247 | Val Acc:0.9901374115588817\n",
      "Epoch:9 | Train Loss:0.019500640461494995 | Train Acc:0.9945201421800948 | Val Loss:0.04320783102686735 | Val Acc:0.9893062945376051\n",
      "Epoch:10 | Train Loss:0.01773022176734816 | Train Acc:0.9951680983412322 | Val Loss:0.03947758831163036 | Val Acc:0.9901374115588817\n",
      "Cost time: 48.601798272132875 mins.\n"
     ]
    }
   ],
   "source": [
    "train_fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 0.029480772674273535 | Test Acc: 0.9918391719745223 |\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(model_path))\n",
    "test_loss, test_acc = evaluate(model, device, test_iterator, criterion)\n",
    "print('| Test Loss: {0} | Test Acc: {1} |'.format(test_loss,test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.get_num_threads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
